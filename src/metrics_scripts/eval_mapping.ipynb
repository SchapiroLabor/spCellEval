{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a0221f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "# import libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import f1_score, matthews_corrcoef, cohen_kappa_score, adjusted_rand_score, normalized_mutual_info_score, confusion_matrix\n",
    "from scipy.spatial.distance import jensenshannon\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f642e2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# calculate the cell type distribution in terms of percentages for predicted and true phenotypes\n",
    "def calculate_cell_type_distribution(df, predictions, true_label):\n",
    "    \"\"\"\n",
    "    Calculate the cell type distribution in terms of percentages for predicted and true phenotypes.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): DataFrame containing the predictions.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame containing the cell type distribution for predicted and true phenotypes.\n",
    "    \"\"\"\n",
    "    # Get the counts and percentages for predicted phenotypes\n",
    "    counts_predicted = predictions.value_counts()\n",
    "    percentages_predicted = counts_predicted / counts_predicted.sum() * 100\n",
    "    predicted_distribution = pd.DataFrame({'cell_type': counts_predicted.index, 'predicted_percentage': percentages_predicted.values})\n",
    "\n",
    "    # Get the counts and percentages for true phenotypes\n",
    "    counts_true = true_label.value_counts()\n",
    "    percentages_true = counts_true / counts_true.sum() * 100\n",
    "    true_distribution = pd.DataFrame({'cell_type': counts_true.index, 'true_percentage': percentages_true.values})\n",
    "\n",
    "    # Merge the two distributions\n",
    "    distribution_df = pd.merge(predicted_distribution, true_distribution, on='cell_type', how='outer').fillna(0)\n",
    "\n",
    "    return distribution_df\n",
    "\n",
    "# calcualte r2 and pearson correlation for the predicted and true phenotypes\n",
    "def calculate_r2_and_pearson(df):\n",
    "    \"\"\"\n",
    "    Calculate R2 and Pearson correlation for the predicted and true phenotypes.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): DataFrame containing the predictions.\n",
    "\n",
    "    Returns:\n",
    "        tuple: R2 and Pearson correlation values.\n",
    "    \"\"\"\n",
    "    # Calculate R2\n",
    "    r2 = df['predicted_percentage'].corr(df['true_percentage']) ** 2\n",
    "\n",
    "    # Calculate Pearson correlation\n",
    "    pearson_corr = df['predicted_percentage'].corr(df['true_percentage'])\n",
    "\n",
    "    return r2, pearson_corr\n",
    "\n",
    "# parse the tree file to get label -> ancestor path mapping\n",
    "def parse_tree_file(file_path: str) -> dict:\n",
    "    \"\"\"Parses a 2-space-indented tree file and returns label -> ancestor path mapping.\"\"\"\n",
    "    with open(file_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    label_to_ancestors = {}\n",
    "    path_stack = []\n",
    "\n",
    "    for line in lines:\n",
    "        stripped = line.lstrip()\n",
    "        indent = len(line) - len(stripped)\n",
    "        level = indent // 2  # Assumes 2 spaces per indent\n",
    "\n",
    "        path_stack = path_stack[:level]\n",
    "        path_stack.append(stripped.strip())\n",
    "\n",
    "        if level >= 2:\n",
    "            label = path_stack[-1]\n",
    "            label_to_ancestors[label] = path_stack[:-1]  # from root to parent\n",
    "\n",
    "    return label_to_ancestors\n",
    "\n",
    "# calculate hierarchical F1 score given ground truths, predictions, and an ancestor map\n",
    "def hierarchical_f1_score(y_true, y_pred, ancestor_map):\n",
    "    \"\"\"Computes hierarchical F1 given ground truths, predictions, and an ancestor map.\"\"\"\n",
    "    scores = []\n",
    "\n",
    "    for true_label, pred_label in zip(y_true, y_pred):\n",
    "        true_anc = set(ancestor_map.get(true_label, []))\n",
    "        pred_anc = set(ancestor_map.get(pred_label, []))\n",
    "\n",
    "        if not true_anc or not pred_anc:\n",
    "            scores.append(0.0)\n",
    "            continue\n",
    "\n",
    "        intersection = true_anc & pred_anc\n",
    "        precision = len(intersection) / len(pred_anc)\n",
    "        recall = len(intersection) / len(true_anc)\n",
    "        f1 = (2 * precision * recall) / (precision + recall) if (precision + recall) else 0.0\n",
    "        scores.append(f1)\n",
    "\n",
    "    return sum(scores) / len(scores)\n",
    "\n",
    "#get level_2 and level_1 for a predicted phenotype\n",
    "def map_predicted_to_levels(predicted_phenotype):\n",
    "    return hierarchy_mappings.get(predicted_phenotype, {'level_2_cell_type': None, 'level_1_cell_type': None})\n",
    "\n",
    "# G-Mean (Geometric Mean of per-class sensitivity)\n",
    "def gmean_score(y_true, y_pred):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        sensitivity = np.diag(cm) / cm.sum(axis=1)\n",
    "        gmean = np.prod(sensitivity[sensitivity > 0]) ** (1 / len(sensitivity[sensitivity > 0]))\n",
    "    return gmean\n",
    "\n",
    "# get the average train and inference time\n",
    "def calculate_time(time_path):\n",
    "\n",
    "    with open(time_path, \"r\") as f:\n",
    "        fold_times = f.readlines()\n",
    "    fold_times = [line.strip() for line in fold_times if line.strip()]\n",
    "\n",
    "    # get average train_time and inference_time and add to the results dataframe\n",
    "    fold_times_dict = {}\n",
    "    for line in fold_times:\n",
    "        line = line.replace(',', ':') \n",
    "        parts = line.split(\":\")\n",
    "        if len(parts) == 2:\n",
    "            fold_name = parts[0].strip()\n",
    "            fold_time = parts[1].strip()\n",
    "            fold_time = float(fold_time.split()[0])  # Assuming the time is in seconds\n",
    "            fold_times_dict[fold_name] = {'time': fold_time}\n",
    "\n",
    "    # in fold times_dict, add the average time for each fold\n",
    "    fold_times_df = pd.DataFrame.from_dict(fold_times_dict, orient='index')\n",
    "    fold_times_df['fold'] = fold_times_df.index\n",
    "    fold_times_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # split fold name on the second \" \" into two new cols\n",
    "    fold_times_df[['fold_name', 'fold_num', 'event']] = fold_times_df['fold'].astype(str).str.split(pat=' ', n=2, expand=True) \n",
    "    #fold_times_df[\"time\"] = fold_times_df[\"time\"].astype(float)\n",
    "\n",
    "    # return the average for all train_time and inference_time\n",
    "    avg_train_time = fold_times_df[\n",
    "        (fold_times_df['event'] == 'train_time') | (fold_times_df['event'] == \"training_time\")\n",
    "        ]['time'].mean()\n",
    "    avg_inference_time = fold_times_df[\n",
    "        (fold_times_df['event'] != 'train_time') | (fold_times_df['event'] != \"training_time\")\n",
    "    ]['time'].mean()\n",
    "\n",
    "    return avg_train_time, avg_inference_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a768077-3087-4775-9ecd-70faccf70d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics_for_methods(methods, levels, base_path):\n",
    "    all_results = []\n",
    "\n",
    "    for method in tqdm(methods, desc=\"Methods\"):\n",
    "        try:\n",
    "            for level in levels:\n",
    "                print(f\"Processing method: {method}, level: {level}\")\n",
    "                path = os.path.join(base_path, method, \"level3\")\n",
    "                \n",
    "                if os.path.exists(path):\n",
    "                    files = [f for f in os.listdir(path) if f.startswith(\"predictions\") and f.endswith(\".csv\")]\n",
    "                else:\n",
    "                    print(f\"Path {path} does not exist. Skipping...\")\n",
    "                    files = []\n",
    "\n",
    "                for file in files:\n",
    "                    file_path = os.path.join(path, file)\n",
    "                    if not os.path.exists(file_path):\n",
    "                        print(f\"File {file_path} does not exist. Skipping...\")\n",
    "                        continue\n",
    "                    df = pd.read_csv(file_path)\n",
    "                    fold_name = os.path.splitext(file)[0]\n",
    "                    if 'cell_type' in df.columns:\n",
    "                        df.rename(columns={'cell_type': 'true_phenotype'}, inplace=True)\n",
    "                        df.to_csv(file_path, index=False)\n",
    "                        print(f\"Updated {file} to rename 'cell_type' to 'true_phenotype'.\")\n",
    "                    else:\n",
    "                        continue                        \n",
    "                    if level == 'level_3':\n",
    "                        true_label = df['true_phenotype']\n",
    "                        predictions = df[\"predicted_phenotype\"]\n",
    "                    else:\n",
    "                        df[f'mapped_{level}_cell_type'] = df['predicted_phenotype'].apply(lambda x: map_predicted_to_levels(x)[f'{level}_cell_type'])\n",
    "                        mask_na = df[f'mapped_{level}_cell_type'].isna()\n",
    "                        df.loc[mask_na, f'mapped_{level}_cell_type'] = df.loc[mask_na, 'predicted_phenotype']\n",
    "\n",
    "                        if f'{level}_cell_type' not in df.columns:\n",
    "                            true_label = df['true_phenotype'].apply(lambda x: map_predicted_to_levels(x)[f'{level}_cell_type'])\n",
    "                        else:\n",
    "                            true_label = df[f'{level}_cell_type']\n",
    "                        \n",
    "                        predictions = df[f'mapped_{level}_cell_type'] \n",
    "\n",
    "                    f1 = f1_score(true_label, predictions, average='weighted')\n",
    "                    accuracy = (true_label == predictions).mean()\n",
    "                    macro_f1 = f1_score(true_label, predictions, average='macro')\n",
    "                    mcc = matthews_corrcoef(true_label, predictions)\n",
    "                    kappa = cohen_kappa_score(true_label, predictions)\n",
    "\n",
    "                    if level == 'level_3':\n",
    "                        ancestor_map = parse_tree_file(\"cell_type_hierarchy.txt\")\n",
    "                        hierarchical_f1 = hierarchical_f1_score(true_label, predictions, ancestor_map)\n",
    "                    else:\n",
    "                        hierarchical_f1 = None\n",
    "                    \n",
    "                    cell_type_distribution = calculate_cell_type_distribution(df, predictions, true_label)\n",
    "                    r2, pearson_corr = calculate_r2_and_pearson(cell_type_distribution)\n",
    "                    ari = adjusted_rand_score(true_label, predictions)\n",
    "                    nmi = normalized_mutual_info_score(true_label, predictions)\n",
    "                    kl_divergence = sum(cell_type_distribution['predicted_percentage'] / 100 * np.log2((cell_type_distribution['predicted_percentage'] + 1e-9) / (cell_type_distribution['true_percentage'] + 1e-9)))\n",
    "                    scaled_kl_mean = 1 / (1 + kl_divergence)\n",
    "                    jensen = jensenshannon(cell_type_distribution['predicted_percentage'] / 100, cell_type_distribution['true_percentage'] / 100, base=2)\n",
    "                    jensen_scaled = 1 - jensen\n",
    "                    g_mean = gmean_score(true_label, predictions)\n",
    "                    \n",
    "                    times_path1 = os.path.join(path, \"fold_times.txt\")\n",
    "                    times_path2 = os.path.join(base_path,method, \"fold_times.txt\")\n",
    "                    if os.path.exists(times_path1):\n",
    "                        average_train_time, average_inference_time = calculate_time(times_path1)\n",
    "                    elif os.path.exists(times_path2):\n",
    "                        average_train_time, average_inference_time = calculate_time(times_path2)\n",
    "                    else:\n",
    "                        average_train_time = None\n",
    "                        average_inference_time = None\n",
    "\n",
    "                    all_results.append({\n",
    "                        'method': method,\n",
    "                        'level': level,\n",
    "                        'fold': fold_name,\n",
    "                        'f1_weighted': f1,\n",
    "                        'hierarchical_f1': hierarchical_f1,\n",
    "                        'accuracy': accuracy,\n",
    "                        'macro_f1': macro_f1,\n",
    "                        'g_mean': g_mean,\n",
    "                        'mcc': mcc,\n",
    "                        'kappa': kappa,\n",
    "                        'r2': r2,\n",
    "                        'pearson_corr': pearson_corr,\n",
    "                        'ari': ari,\n",
    "                        'nmi': nmi,\n",
    "                        'jsd': jensen,\n",
    "                        'jsd_scaled': jensen_scaled,\n",
    "                        'kl_divergence': kl_divergence,\n",
    "                        'kl_scaled': scaled_kl_mean,\n",
    "                        'train_time': average_train_time,\n",
    "                        'inference_time':average_inference_time\n",
    "                    })\n",
    "            print(f\"Finished processing method: {method}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error encountered for method {method}: {e}. Skipping this method.\")\n",
    "            continue\n",
    "\n",
    "    return pd.DataFrame(all_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b365feda-9732-484f-9fb4-762ac4fd03b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics_for_methods(methods, levels, base_path):\n",
    "    all_results = []\n",
    "\n",
    "    for method in tqdm(methods, desc=\"Methods\"):\n",
    "        try:\n",
    "            for level in levels:\n",
    "                print(f\"Processing method: {method}, level: {level}\")\n",
    "                path = os.path.join(base_path, method, \"level3\")\n",
    "                \n",
    "                if os.path.exists(path):\n",
    "                    files = [f for f in os.listdir(path) if f.startswith(\"predictions\") and f.endswith(\".csv\")]\n",
    "                else:\n",
    "                    print(f\"Path {path} does not exist. Skipping...\")\n",
    "                    files = []\n",
    "\n",
    "                for file in files:\n",
    "                    file_path = os.path.join(path, file)\n",
    "                    if not os.path.exists(file_path):\n",
    "                        print(f\"File {file_path} does not exist. Skipping...\")\n",
    "                        continue\n",
    "                    df = pd.read_csv(file_path)\n",
    "                    fold_name = os.path.splitext(file)[0]\n",
    "                    \n",
    "                    if level == 'level_3':\n",
    "                        true_label = df['true_phenotype']\n",
    "                        predictions = df[\"predicted_phenotype\"]\n",
    "                    else:\n",
    "                        df[f'mapped_{level}_cell_type'] = df['predicted_phenotype'].apply(lambda x: map_predicted_to_levels(x)[f'{level}_cell_type'])\n",
    "                        mask_na = df[f'mapped_{level}_cell_type'].isna()\n",
    "                        df.loc[mask_na, f'mapped_{level}_cell_type'] = df.loc[mask_na, 'predicted_phenotype']\n",
    "\n",
    "                        if f'{level}_cell_type' not in df.columns:\n",
    "                            true_label = df['true_phenotype'].apply(lambda x: map_predicted_to_levels(x)[f'{level}_cell_type'])\n",
    "                        else:\n",
    "                            true_label = df[f'{level}_cell_type']\n",
    "                        \n",
    "                        predictions = df[f'mapped_{level}_cell_type'] \n",
    "\n",
    "                    f1 = f1_score(true_label, predictions, average='weighted')\n",
    "                    accuracy = (true_label == predictions).mean()\n",
    "                    macro_f1 = f1_score(true_label, predictions, average='macro')\n",
    "                    mcc = matthews_corrcoef(true_label, predictions)\n",
    "                    kappa = cohen_kappa_score(true_label, predictions)\n",
    "\n",
    "                    if level == 'level_3':\n",
    "                        ancestor_map = parse_tree_file(\"cell_type_hierarchy.txt\")\n",
    "                        hierarchical_f1 = hierarchical_f1_score(true_label, predictions, ancestor_map)\n",
    "                    else:\n",
    "                        hierarchical_f1 = None\n",
    "                    \n",
    "                    cell_type_distribution = calculate_cell_type_distribution(df, predictions, true_label)\n",
    "                    r2, pearson_corr = calculate_r2_and_pearson(cell_type_distribution)\n",
    "                    ari = adjusted_rand_score(true_label, predictions)\n",
    "                    nmi = normalized_mutual_info_score(true_label, predictions)\n",
    "                    kl_divergence = sum(cell_type_distribution['predicted_percentage'] / 100 * np.log2((cell_type_distribution['predicted_percentage'] + 1e-9) / (cell_type_distribution['true_percentage'] + 1e-9)))\n",
    "                    scaled_kl_mean = 1 / (1 + kl_divergence)\n",
    "                    jensen = jensenshannon(cell_type_distribution['predicted_percentage'] / 100, cell_type_distribution['true_percentage'] / 100, base=2)\n",
    "                    jensen_scaled = 1 - jensen\n",
    "                    g_mean = gmean_score(true_label, predictions)\n",
    "                    \n",
    "                    times_path1 = os.path.join(path, \"fold_times.txt\")\n",
    "                    times_path2 = os.path.join(base_path,method, \"fold_times.txt\")\n",
    "                    if os.path.exists(times_path1):\n",
    "                        average_train_time, average_inference_time = calculate_time(times_path1)\n",
    "                    elif os.path.exists(times_path2):\n",
    "                        average_train_time, average_inference_time = calculate_time(times_path2)\n",
    "                    else:\n",
    "                        average_train_time = None\n",
    "                        average_inference_time = None\n",
    "\n",
    "                    all_results.append({\n",
    "                        'method': method,\n",
    "                        'level': level,\n",
    "                        'fold': fold_name,\n",
    "                        'f1_weighted': f1,\n",
    "                        'hierarchical_f1': hierarchical_f1,\n",
    "                        'accuracy': accuracy,\n",
    "                        'macro_f1': macro_f1,\n",
    "                        'g_mean': g_mean,\n",
    "                        'mcc': mcc,\n",
    "                        'kappa': kappa,\n",
    "                        'r2': r2,\n",
    "                        'pearson_corr': pearson_corr,\n",
    "                        'ari': ari,\n",
    "                        'nmi': nmi,\n",
    "                        'jsd': jensen,\n",
    "                        'jsd_scaled': jensen_scaled,\n",
    "                        'kl_divergence': kl_divergence,\n",
    "                        'kl_scaled': scaled_kl_mean,\n",
    "                        'train_time': average_train_time,\n",
    "                        'inference_time':average_inference_time\n",
    "                    })\n",
    "            print(f\"Finished processing method: {method}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error encountered for method {method}: {e}. Skipping this method.\")\n",
    "            continue\n",
    "\n",
    "    return pd.DataFrame(all_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "47b9cbc4-546d-4f35-9c6d-55bbb4fc6434",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the hierarchy mappings from the file\n",
    "with open('hierarchy_mappings.pkl', 'rb') as f:\n",
    "    import pickle\n",
    "    hierarchy_mappings = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc4738ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Methods:   0%|          | 0/34 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing method: phenograph_80, level: level_1\n",
      "Processing method: phenograph_80, level: level_2\n",
      "Processing method: phenograph_80, level: level_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Methods:   3%|▎         | 1/34 [03:09<1:44:27, 189.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing method: phenograph_80\n",
      "Processing method: maps, level: level_1\n",
      "Processing method: maps, level: level_2\n",
      "Processing method: maps, level: level_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Methods:   6%|▌         | 2/34 [04:49<1:13:04, 137.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing method: maps\n",
      "Processing method: phenograph_40, level: level_1\n",
      "Processing method: phenograph_40, level: level_2\n",
      "Processing method: phenograph_40, level: level_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Methods:   9%|▉         | 3/34 [07:59<1:23:05, 160.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing method: phenograph_40\n",
      "Processing method: flowsom_meta_clusters, level: level_1\n",
      "Processing method: flowsom_meta_clusters, level: level_2\n",
      "Processing method: flowsom_meta_clusters, level: level_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Methods:  12%|█▏        | 4/34 [11:06<1:25:38, 171.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing method: flowsom_meta_clusters\n",
      "Processing method: scyan, level: level_1\n",
      "Processing method: scyan, level: level_2\n",
      "Processing method: scyan, level: level_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Methods:  15%|█▍        | 5/34 [14:21<1:26:55, 179.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing method: scyan\n",
      "Processing method: phenograph_20, level: level_1\n",
      "Processing method: phenograph_20, level: level_2\n",
      "Processing method: phenograph_20, level: level_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Methods:  18%|█▊        | 6/34 [17:30<1:25:28, 183.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing method: phenograph_20\n",
      "Processing method: tacit, level: level_1\n",
      "Processing method: tacit, level: level_2\n",
      "Processing method: tacit, level: level_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Methods:  21%|██        | 7/34 [20:10<1:18:53, 175.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing method: tacit\n",
      "Processing method: nimbus_phenograph_40, level: level_1\n",
      "Processing method: nimbus_phenograph_40, level: level_2\n",
      "Processing method: nimbus_phenograph_40, level: level_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Methods:  24%|██▎       | 8/34 [22:38<1:12:18, 166.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing method: nimbus_phenograph_40\n",
      "Processing method: deepcelltypes_adapted, level: level_1\n",
      "Processing method: deepcelltypes_adapted, level: level_2\n",
      "Processing method: deepcelltypes_adapted, level: level_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Methods:  26%|██▋       | 9/34 [24:45<1:04:15, 154.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing method: deepcelltypes_adapted\n",
      "Processing method: .ipynb_checkpoints, level: level_1\n",
      "Path ../results/IMMUcan/.ipynb_checkpoints/level3 does not exist. Skipping...\n",
      "Processing method: .ipynb_checkpoints, level: level_2\n",
      "Path ../results/IMMUcan/.ipynb_checkpoints/level3 does not exist. Skipping...\n",
      "Processing method: .ipynb_checkpoints, level: level_3\n",
      "Path ../results/IMMUcan/.ipynb_checkpoints/level3 does not exist. Skipping...\n",
      "Finished processing method: .ipynb_checkpoints\n",
      "Processing method: cellsighter, level: level_1\n",
      "Processing method: cellsighter, level: level_2\n",
      "Processing method: cellsighter, level: level_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Methods:  32%|███▏      | 11/34 [26:51<42:36, 111.14s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing method: cellsighter\n",
      "Processing method: astir, level: level_1\n",
      "Processing method: astir, level: level_2\n",
      "Processing method: astir, level: level_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Methods:  35%|███▌      | 12/34 [29:32<45:24, 123.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing method: astir\n",
      "Processing method: nimbus_FuseSOM_15, level: level_1\n",
      "Processing method: nimbus_FuseSOM_15, level: level_2\n",
      "Processing method: nimbus_FuseSOM_15, level: level_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Methods:  38%|███▊      | 13/34 [32:01<45:40, 130.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing method: nimbus_FuseSOM_15\n",
      "Processing method: leiden_res0_5, level: level_1\n",
      "Processing method: leiden_res0_5, level: level_2\n",
      "Processing method: leiden_res0_5, level: level_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Methods:  41%|████      | 14/34 [34:38<45:55, 137.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing method: leiden_res0_5\n",
      "Processing method: random_forest_default_StratifiedGroupKFold, level: level_1\n",
      "Processing method: random_forest_default_StratifiedGroupKFold, level: level_2\n",
      "Processing method: random_forest_default_StratifiedGroupKFold, level: level_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Methods:  44%|████▍     | 15/34 [36:27<41:00, 129.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing method: random_forest_default_StratifiedGroupKFold\n",
      "Processing method: leiden_res2_0, level: level_1\n",
      "Processing method: leiden_res2_0, level: level_2\n",
      "Processing method: leiden_res2_0, level: level_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Methods:  47%|████▋     | 16/34 [39:04<41:15, 137.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing method: leiden_res2_0\n",
      "Processing method: nimbus_leiden_0_8, level: level_1\n",
      "Processing method: nimbus_leiden_0_8, level: level_2\n",
      "Processing method: nimbus_leiden_0_8, level: level_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Methods:  50%|█████     | 17/34 [41:34<40:01, 141.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing method: nimbus_leiden_0_8\n",
      "Processing method: nimbus, level: level_1\n",
      "Path ../results/IMMUcan/nimbus/level3 does not exist. Skipping...\n",
      "Processing method: nimbus, level: level_2\n",
      "Path ../results/IMMUcan/nimbus/level3 does not exist. Skipping...\n",
      "Processing method: nimbus, level: level_3\n",
      "Path ../results/IMMUcan/nimbus/level3 does not exist. Skipping...\n",
      "Finished processing method: nimbus\n",
      "Processing method: most_frequent_default_StratifiedGroupKFold, level: level_1\n",
      "Processing method: most_frequent_default_StratifiedGroupKFold, level: level_2\n",
      "Processing method: most_frequent_default_StratifiedGroupKFold, level: level_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Methods:  56%|█████▌    | 19/34 [43:15<24:58, 99.90s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing method: most_frequent_default_StratifiedGroupKFold\n",
      "Processing method: flowsom, level: level_1\n",
      "Processing method: flowsom, level: level_2\n",
      "Processing method: flowsom, level: level_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Methods:  59%|█████▉    | 20/34 [46:25<28:29, 122.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing method: flowsom\n",
      "Processing method: stratified_default_StratifiedGroupKFold, level: level_1\n",
      "Processing method: stratified_default_StratifiedGroupKFold, level: level_2\n",
      "Processing method: stratified_default_StratifiedGroupKFold, level: level_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Methods:  62%|██████▏   | 21/34 [48:14<25:42, 118.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing method: stratified_default_StratifiedGroupKFold\n",
      "Processing method: leiden_res1_0, level: level_1\n",
      "Processing method: leiden_res1_0, level: level_2\n",
      "Processing method: leiden_res1_0, level: level_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Methods:  65%|██████▍   | 22/34 [50:52<25:50, 129.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing method: leiden_res1_0\n",
      "Processing method: xgboost_default_StratifiedGroupKFold, level: level_1\n",
      "Processing method: xgboost_default_StratifiedGroupKFold, level: level_2\n",
      "Processing method: xgboost_default_StratifiedGroupKFold, level: level_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Methods:  68%|██████▊   | 23/34 [52:43<22:45, 124.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing method: xgboost_default_StratifiedGroupKFold\n",
      "Processing method: ribca_adapted, level: level_1\n",
      "Processing method: ribca_adapted, level: level_2\n",
      "Processing method: ribca_adapted, level: level_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Methods:  71%|███████   | 24/34 [53:39<17:27, 104.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing method: ribca_adapted\n",
      "Processing method: leiden_res0_8, level: level_1\n",
      "Processing method: leiden_res0_8, level: level_2\n",
      "Processing method: leiden_res0_8, level: level_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Methods:  74%|███████▎  | 25/34 [56:17<18:02, 120.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing method: leiden_res0_8\n",
      "Processing method: tribus, level: level_1\n",
      "Processing method: tribus, level: level_2\n",
      "Processing method: tribus, level: level_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Methods:  76%|███████▋  | 26/34 [58:55<17:29, 131.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing method: tribus\n",
      "Processing method: phenograph_30, level: level_1\n",
      "Processing method: phenograph_30, level: level_2\n",
      "Processing method: phenograph_30, level: level_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Methods:  79%|███████▉  | 27/34 [1:02:05<17:18, 148.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing method: phenograph_30\n",
      "Processing method: celllens_full, level: level_1\n",
      "Processing method: celllens_full, level: level_2\n",
      "Processing method: celllens_full, level: level_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Methods:  82%|████████▏ | 28/34 [1:04:49<15:18, 153.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing method: celllens_full\n",
      "Processing method: FuseSOM_15, level: level_1\n",
      "Processing method: FuseSOM_15, level: level_2\n",
      "Processing method: FuseSOM_15, level: level_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Methods:  85%|████████▌ | 29/34 [1:07:28<12:54, 154.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing method: FuseSOM_15\n",
      "Processing method: logistic_regression_default_StratifiedGroupKFold, level: level_1\n",
      "Processing method: logistic_regression_default_StratifiedGroupKFold, level: level_2\n",
      "Processing method: logistic_regression_default_StratifiedGroupKFold, level: level_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Methods:  88%|████████▊ | 30/34 [1:09:18<09:25, 141.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing method: logistic_regression_default_StratifiedGroupKFold\n",
      "Processing method: deepcelltypes, level: level_1\n",
      "Processing method: deepcelltypes, level: level_2\n",
      "Processing method: deepcelltypes, level: level_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Methods:  91%|█████████ | 31/34 [1:11:58<07:20, 147.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing method: deepcelltypes\n",
      "Processing method: nimbus_flowsom, level: level_1\n",
      "Processing method: nimbus_flowsom, level: level_2\n",
      "Processing method: nimbus_flowsom, level: level_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Methods:  94%|█████████▍| 32/34 [1:14:28<04:55, 147.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing method: nimbus_flowsom\n",
      "Processing method: ribca, level: level_1\n",
      "Processing method: ribca, level: level_2\n",
      "Processing method: ribca, level: level_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Methods:  97%|█████████▋| 33/34 [1:15:33<02:03, 123.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing method: ribca\n",
      "Processing method: CellLENS_Lite, level: level_1\n",
      "Processing method: CellLENS_Lite, level: level_2\n",
      "Processing method: CellLENS_Lite, level: level_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Methods: 100%|██████████| 34/34 [1:18:13<00:00, 138.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing method: CellLENS_Lite\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "base_path = \"../results/IMMUcan\"\n",
    "levels = ['level_1', 'level_2', 'level_3']\n",
    "\n",
    "#make a list of folders in the base_path\n",
    "methods = [f for f in os.listdir(base_path) if os.path.isdir(os.path.join(base_path, f))]\n",
    "\n",
    "# Calculate metrics for all methods and levels\n",
    "results = calculate_metrics_for_methods(methods, levels, base_path)\n",
    "\n",
    "# Get the average of the metrics for each method and level, excluding the 'fold' column\n",
    "average_results = results.drop(columns=[\"fold\"]).groupby(['method', 'level'], as_index=False).mean()\n",
    "# Get the standard deviation of the metrics for each method and level\n",
    "std_results = results.drop(columns=[\"fold\"]).groupby(['method', 'level']).std().reset_index()\n",
    "# Merge the average and standard deviation results\n",
    "final_results = pd.merge(average_results, std_results, on=['method', 'level'], suffixes=('_mean', '_std'))\n",
    "\n",
    "# calculate a stability metric for the methods where s = (1 - std/stability_thresh)\n",
    "stability_thresh = 0.2\n",
    "final_results['stability'] = 1 - (final_results['f1_weighted_std'] / stability_thresh)\n",
    "# set to 0 if negative\n",
    "final_results.loc[final_results['stability'] < 0, 'stability'] = 0\n",
    "\n",
    "# Save the final results to a CSV file with ';' as the separator\n",
    "final_results.to_csv(os.path.join(base_path, \"final_results.csv\"), index=False, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c59c8060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate in a new col overall score from all the scores and sort descending\n",
    "final_results['overall_score_mean'] = (final_results['f1_weighted_mean'] + final_results['accuracy_mean'] + \n",
    "                                   final_results['macro_f1_mean'] + final_results['mcc_mean'] + \n",
    "                                   final_results['kappa_mean'] + final_results['r2_mean'] + \n",
    "                                   final_results['pearson_corr_mean'] + final_results['ari_mean'] + \n",
    "                                   final_results['stability']) / 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f84528f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>level</th>\n",
       "      <th>f1_weighted_mean</th>\n",
       "      <th>hierarchical_f1_mean</th>\n",
       "      <th>accuracy_mean</th>\n",
       "      <th>macro_f1_mean</th>\n",
       "      <th>g_mean_mean</th>\n",
       "      <th>mcc_mean</th>\n",
       "      <th>kappa_mean</th>\n",
       "      <th>r2_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>ari_std</th>\n",
       "      <th>nmi_std</th>\n",
       "      <th>jsd_std</th>\n",
       "      <th>jsd_scaled_std</th>\n",
       "      <th>kl_divergence_std</th>\n",
       "      <th>kl_scaled_std</th>\n",
       "      <th>train_time_std</th>\n",
       "      <th>inference_time_std</th>\n",
       "      <th>stability</th>\n",
       "      <th>overall_score_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CellLENS_Lite</td>\n",
       "      <td>level_1</td>\n",
       "      <td>0.795586</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.811839</td>\n",
       "      <td>0.593905</td>\n",
       "      <td>0.724235</td>\n",
       "      <td>0.696093</td>\n",
       "      <td>0.691456</td>\n",
       "      <td>0.961711</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023751</td>\n",
       "      <td>0.021674</td>\n",
       "      <td>0.024221</td>\n",
       "      <td>0.024221</td>\n",
       "      <td>0.018878</td>\n",
       "      <td>0.016816</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.946108</td>\n",
       "      <td>0.782111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CellLENS_Lite</td>\n",
       "      <td>level_2</td>\n",
       "      <td>0.764736</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.785496</td>\n",
       "      <td>0.592056</td>\n",
       "      <td>0.663559</td>\n",
       "      <td>0.683480</td>\n",
       "      <td>0.679137</td>\n",
       "      <td>0.983864</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022771</td>\n",
       "      <td>0.016064</td>\n",
       "      <td>0.022851</td>\n",
       "      <td>0.022851</td>\n",
       "      <td>0.018706</td>\n",
       "      <td>0.016456</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.953190</td>\n",
       "      <td>0.780483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CellLENS_Lite</td>\n",
       "      <td>level_3</td>\n",
       "      <td>0.666797</td>\n",
       "      <td>0.775340</td>\n",
       "      <td>0.703598</td>\n",
       "      <td>0.486879</td>\n",
       "      <td>0.461948</td>\n",
       "      <td>0.597235</td>\n",
       "      <td>0.592547</td>\n",
       "      <td>0.974513</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020044</td>\n",
       "      <td>0.016026</td>\n",
       "      <td>0.029031</td>\n",
       "      <td>0.029031</td>\n",
       "      <td>0.038581</td>\n",
       "      <td>0.027781</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.943752</td>\n",
       "      <td>0.729602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FuseSOM_15</td>\n",
       "      <td>level_1</td>\n",
       "      <td>0.806554</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.824054</td>\n",
       "      <td>0.602036</td>\n",
       "      <td>0.814648</td>\n",
       "      <td>0.712393</td>\n",
       "      <td>0.710701</td>\n",
       "      <td>0.995601</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.803562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FuseSOM_15</td>\n",
       "      <td>level_2</td>\n",
       "      <td>0.769324</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.781365</td>\n",
       "      <td>0.600316</td>\n",
       "      <td>0.772793</td>\n",
       "      <td>0.685472</td>\n",
       "      <td>0.681155</td>\n",
       "      <td>0.936103</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.778476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>tribus</td>\n",
       "      <td>level_2</td>\n",
       "      <td>0.689865</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.683836</td>\n",
       "      <td>0.531833</td>\n",
       "      <td>0.266300</td>\n",
       "      <td>0.559993</td>\n",
       "      <td>0.550454</td>\n",
       "      <td>0.796052</td>\n",
       "      <td>...</td>\n",
       "      <td>0.059058</td>\n",
       "      <td>0.061256</td>\n",
       "      <td>0.034477</td>\n",
       "      <td>0.034477</td>\n",
       "      <td>0.051491</td>\n",
       "      <td>0.041068</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.800445</td>\n",
       "      <td>0.657232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>tribus</td>\n",
       "      <td>level_3</td>\n",
       "      <td>0.611721</td>\n",
       "      <td>0.664520</td>\n",
       "      <td>0.576541</td>\n",
       "      <td>0.385603</td>\n",
       "      <td>0.296823</td>\n",
       "      <td>0.463314</td>\n",
       "      <td>0.455693</td>\n",
       "      <td>0.865220</td>\n",
       "      <td>...</td>\n",
       "      <td>0.049136</td>\n",
       "      <td>0.041565</td>\n",
       "      <td>0.031878</td>\n",
       "      <td>0.031878</td>\n",
       "      <td>0.138165</td>\n",
       "      <td>0.056139</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.798031</td>\n",
       "      <td>0.620362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>xgboost_default_StratifiedGroupKFold</td>\n",
       "      <td>level_1</td>\n",
       "      <td>0.947002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.946750</td>\n",
       "      <td>0.907800</td>\n",
       "      <td>0.912472</td>\n",
       "      <td>0.915787</td>\n",
       "      <td>0.914977</td>\n",
       "      <td>0.991828</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011789</td>\n",
       "      <td>0.012027</td>\n",
       "      <td>0.003910</td>\n",
       "      <td>0.003910</td>\n",
       "      <td>0.000678</td>\n",
       "      <td>0.000676</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.979361</td>\n",
       "      <td>0.939827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>xgboost_default_StratifiedGroupKFold</td>\n",
       "      <td>level_2</td>\n",
       "      <td>0.938819</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.938269</td>\n",
       "      <td>0.905050</td>\n",
       "      <td>0.914320</td>\n",
       "      <td>0.912231</td>\n",
       "      <td>0.911607</td>\n",
       "      <td>0.995858</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010951</td>\n",
       "      <td>0.010503</td>\n",
       "      <td>0.003531</td>\n",
       "      <td>0.003531</td>\n",
       "      <td>0.000628</td>\n",
       "      <td>0.000626</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.979888</td>\n",
       "      <td>0.938033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>xgboost_default_StratifiedGroupKFold</td>\n",
       "      <td>level_3</td>\n",
       "      <td>0.925801</td>\n",
       "      <td>0.936042</td>\n",
       "      <td>0.924738</td>\n",
       "      <td>0.883379</td>\n",
       "      <td>0.904464</td>\n",
       "      <td>0.901992</td>\n",
       "      <td>0.901470</td>\n",
       "      <td>0.999103</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010562</td>\n",
       "      <td>0.006439</td>\n",
       "      <td>0.002845</td>\n",
       "      <td>0.002845</td>\n",
       "      <td>0.000597</td>\n",
       "      <td>0.000593</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.981877</td>\n",
       "      <td>0.932366</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  method    level  f1_weighted_mean  \\\n",
       "0                          CellLENS_Lite  level_1          0.795586   \n",
       "1                          CellLENS_Lite  level_2          0.764736   \n",
       "2                          CellLENS_Lite  level_3          0.666797   \n",
       "3                             FuseSOM_15  level_1          0.806554   \n",
       "4                             FuseSOM_15  level_2          0.769324   \n",
       "..                                   ...      ...               ...   \n",
       "91                                tribus  level_2          0.689865   \n",
       "92                                tribus  level_3          0.611721   \n",
       "93  xgboost_default_StratifiedGroupKFold  level_1          0.947002   \n",
       "94  xgboost_default_StratifiedGroupKFold  level_2          0.938819   \n",
       "95  xgboost_default_StratifiedGroupKFold  level_3          0.925801   \n",
       "\n",
       "    hierarchical_f1_mean  accuracy_mean  macro_f1_mean  g_mean_mean  mcc_mean  \\\n",
       "0                    NaN       0.811839       0.593905     0.724235  0.696093   \n",
       "1                    NaN       0.785496       0.592056     0.663559  0.683480   \n",
       "2               0.775340       0.703598       0.486879     0.461948  0.597235   \n",
       "3                    NaN       0.824054       0.602036     0.814648  0.712393   \n",
       "4                    NaN       0.781365       0.600316     0.772793  0.685472   \n",
       "..                   ...            ...            ...          ...       ...   \n",
       "91                   NaN       0.683836       0.531833     0.266300  0.559993   \n",
       "92              0.664520       0.576541       0.385603     0.296823  0.463314   \n",
       "93                   NaN       0.946750       0.907800     0.912472  0.915787   \n",
       "94                   NaN       0.938269       0.905050     0.914320  0.912231   \n",
       "95              0.936042       0.924738       0.883379     0.904464  0.901992   \n",
       "\n",
       "    kappa_mean   r2_mean  ...   ari_std   nmi_std   jsd_std  jsd_scaled_std  \\\n",
       "0     0.691456  0.961711  ...  0.023751  0.021674  0.024221        0.024221   \n",
       "1     0.679137  0.983864  ...  0.022771  0.016064  0.022851        0.022851   \n",
       "2     0.592547  0.974513  ...  0.020044  0.016026  0.029031        0.029031   \n",
       "3     0.710701  0.995601  ...  0.000000  0.000000  0.000000        0.000000   \n",
       "4     0.681155  0.936103  ...  0.000000  0.000000  0.000000        0.000000   \n",
       "..         ...       ...  ...       ...       ...       ...             ...   \n",
       "91    0.550454  0.796052  ...  0.059058  0.061256  0.034477        0.034477   \n",
       "92    0.455693  0.865220  ...  0.049136  0.041565  0.031878        0.031878   \n",
       "93    0.914977  0.991828  ...  0.011789  0.012027  0.003910        0.003910   \n",
       "94    0.911607  0.995858  ...  0.010951  0.010503  0.003531        0.003531   \n",
       "95    0.901470  0.999103  ...  0.010562  0.006439  0.002845        0.002845   \n",
       "\n",
       "    kl_divergence_std  kl_scaled_std  train_time_std  inference_time_std  \\\n",
       "0            0.018878       0.016816             NaN                 0.0   \n",
       "1            0.018706       0.016456             NaN                 0.0   \n",
       "2            0.038581       0.027781             NaN                 0.0   \n",
       "3            0.000000       0.000000             NaN                 0.0   \n",
       "4            0.000000       0.000000             NaN                 0.0   \n",
       "..                ...            ...             ...                 ...   \n",
       "91           0.051491       0.041068             NaN                 0.0   \n",
       "92           0.138165       0.056139             NaN                 0.0   \n",
       "93           0.000678       0.000676             0.0                 0.0   \n",
       "94           0.000628       0.000626             0.0                 0.0   \n",
       "95           0.000597       0.000593             0.0                 0.0   \n",
       "\n",
       "    stability  overall_score_mean  \n",
       "0    0.946108            0.782111  \n",
       "1    0.953190            0.780483  \n",
       "2    0.943752            0.729602  \n",
       "3    1.000000            0.803562  \n",
       "4    1.000000            0.778476  \n",
       "..        ...                 ...  \n",
       "91   0.800445            0.657232  \n",
       "92   0.798031            0.620362  \n",
       "93   0.979361            0.939827  \n",
       "94   0.979888            0.938033  \n",
       "95   0.981877            0.932366  \n",
       "\n",
       "[96 rows x 38 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cdf36d73-b1ba-42e0-a0af-5b29825eb55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the final results to a CSV file with ';' as the separator\n",
    "final_results.to_csv(os.path.join(base_path, \"final_results.csv\"), index=False, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "8d9498ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metric categories and their sub-metrics with weights\n",
    "metrics_wt = {\n",
    "    \"Classification Performance\": {\n",
    "        \"macro_f1_mean\": 0.1,\n",
    "        \"mcc_mean\": 0.10,\n",
    "        \"kappa_mean\": 0.1,\n",
    "        \"f1_weighted_mean\": 0.06,\n",
    "        \"accuracy_mean\": 0.04\n",
    "    },\n",
    "    \"Cell Type Composition\": {\n",
    "        \"r2_mean\": 0.06,\n",
    "        \"pearson_corr_mean\": 0.06,\n",
    "        \"ari_mean\": 0.09,\n",
    "        \"nmi_mean\": 0.09\n",
    "    },\n",
    "    \"Stability\": {\n",
    "        \"stability\": 0.2\n",
    "    },\n",
    "    \"Scalability\": {\n",
    "        \"runtime\": 0.10\n",
    "    }\n",
    "}\n",
    "\n",
    "# calculate the weighted score for each method, only if the metric is present in final_results\n",
    "def calculate_weighted_score(row, metrics_wt):\n",
    "    score = 0\n",
    "    for category, metrics in metrics_wt.items():\n",
    "        for metric, weight in metrics.items():\n",
    "            if metric in row:\n",
    "                score += row[metric] * weight\n",
    "    return score\n",
    "\n",
    "# Apply the weighted score calculation\n",
    "final_results['weighted_score'] = final_results.apply(lambda row: calculate_weighted_score(row, metrics_wt), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5843e516",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>level</th>\n",
       "      <th>f1_weighted_mean</th>\n",
       "      <th>hierarchial_f1_mean</th>\n",
       "      <th>accuracy_mean</th>\n",
       "      <th>macro_f1_mean</th>\n",
       "      <th>mcc_mean</th>\n",
       "      <th>kappa_mean</th>\n",
       "      <th>r2_mean</th>\n",
       "      <th>pearson_corr_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>kappa_std</th>\n",
       "      <th>r2_std</th>\n",
       "      <th>pearson_corr_std</th>\n",
       "      <th>ari_std</th>\n",
       "      <th>nmi_std</th>\n",
       "      <th>jsd_std</th>\n",
       "      <th>jsd_scaled_std</th>\n",
       "      <th>kl_divergence_std</th>\n",
       "      <th>kl_scaled_std</th>\n",
       "      <th>stability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>celllens_LITE</td>\n",
       "      <td>level_1</td>\n",
       "      <td>0.788653</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.803389</td>\n",
       "      <td>0.469044</td>\n",
       "      <td>0.684407</td>\n",
       "      <td>0.679668</td>\n",
       "      <td>0.963801</td>\n",
       "      <td>0.981643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027585</td>\n",
       "      <td>0.029180</td>\n",
       "      <td>0.014906</td>\n",
       "      <td>0.031867</td>\n",
       "      <td>0.029341</td>\n",
       "      <td>0.020956</td>\n",
       "      <td>0.020956</td>\n",
       "      <td>0.020155</td>\n",
       "      <td>0.017381</td>\n",
       "      <td>0.840763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>celllens_LITE</td>\n",
       "      <td>level_2</td>\n",
       "      <td>0.755216</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.777380</td>\n",
       "      <td>0.479881</td>\n",
       "      <td>0.672814</td>\n",
       "      <td>0.668232</td>\n",
       "      <td>0.973147</td>\n",
       "      <td>0.986401</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024798</td>\n",
       "      <td>0.027795</td>\n",
       "      <td>0.014147</td>\n",
       "      <td>0.022455</td>\n",
       "      <td>0.023145</td>\n",
       "      <td>0.023286</td>\n",
       "      <td>0.023286</td>\n",
       "      <td>0.030208</td>\n",
       "      <td>0.024901</td>\n",
       "      <td>0.810616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>celllens_LITE</td>\n",
       "      <td>level_3</td>\n",
       "      <td>0.659848</td>\n",
       "      <td>0.766450</td>\n",
       "      <td>0.698724</td>\n",
       "      <td>0.446223</td>\n",
       "      <td>0.591576</td>\n",
       "      <td>0.586953</td>\n",
       "      <td>0.971893</td>\n",
       "      <td>0.985812</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028483</td>\n",
       "      <td>0.017932</td>\n",
       "      <td>0.009128</td>\n",
       "      <td>0.022721</td>\n",
       "      <td>0.023710</td>\n",
       "      <td>0.029634</td>\n",
       "      <td>0.029634</td>\n",
       "      <td>0.047499</td>\n",
       "      <td>0.033332</td>\n",
       "      <td>0.766545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>celllens_full</td>\n",
       "      <td>level_1</td>\n",
       "      <td>0.766359</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.775488</td>\n",
       "      <td>0.439271</td>\n",
       "      <td>0.650596</td>\n",
       "      <td>0.641313</td>\n",
       "      <td>0.907938</td>\n",
       "      <td>0.952580</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019974</td>\n",
       "      <td>0.048689</td>\n",
       "      <td>0.025720</td>\n",
       "      <td>0.017163</td>\n",
       "      <td>0.011848</td>\n",
       "      <td>0.020896</td>\n",
       "      <td>0.020896</td>\n",
       "      <td>0.033841</td>\n",
       "      <td>0.027113</td>\n",
       "      <td>0.881787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>celllens_full</td>\n",
       "      <td>level_2</td>\n",
       "      <td>0.709971</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.733022</td>\n",
       "      <td>0.427790</td>\n",
       "      <td>0.612692</td>\n",
       "      <td>0.604567</td>\n",
       "      <td>0.923177</td>\n",
       "      <td>0.960582</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020131</td>\n",
       "      <td>0.045940</td>\n",
       "      <td>0.023949</td>\n",
       "      <td>0.026425</td>\n",
       "      <td>0.032952</td>\n",
       "      <td>0.036462</td>\n",
       "      <td>0.036462</td>\n",
       "      <td>0.055323</td>\n",
       "      <td>0.042674</td>\n",
       "      <td>0.861932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>tribus</td>\n",
       "      <td>level_2</td>\n",
       "      <td>0.703929</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.695485</td>\n",
       "      <td>0.539610</td>\n",
       "      <td>0.584846</td>\n",
       "      <td>0.572785</td>\n",
       "      <td>0.739327</td>\n",
       "      <td>0.857539</td>\n",
       "      <td>...</td>\n",
       "      <td>0.035974</td>\n",
       "      <td>0.117236</td>\n",
       "      <td>0.070298</td>\n",
       "      <td>0.040377</td>\n",
       "      <td>0.025030</td>\n",
       "      <td>0.022567</td>\n",
       "      <td>0.022567</td>\n",
       "      <td>0.042518</td>\n",
       "      <td>0.031922</td>\n",
       "      <td>0.777785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>tribus</td>\n",
       "      <td>level_3</td>\n",
       "      <td>0.633979</td>\n",
       "      <td>0.678457</td>\n",
       "      <td>0.597261</td>\n",
       "      <td>0.429557</td>\n",
       "      <td>0.496122</td>\n",
       "      <td>0.488219</td>\n",
       "      <td>0.870576</td>\n",
       "      <td>0.932585</td>\n",
       "      <td>...</td>\n",
       "      <td>0.034828</td>\n",
       "      <td>0.060071</td>\n",
       "      <td>0.032814</td>\n",
       "      <td>0.029950</td>\n",
       "      <td>0.017437</td>\n",
       "      <td>0.027970</td>\n",
       "      <td>0.027970</td>\n",
       "      <td>0.138567</td>\n",
       "      <td>0.057350</td>\n",
       "      <td>0.760949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>xgboost_default_StratifiedGroupKFold</td>\n",
       "      <td>level_1</td>\n",
       "      <td>0.947002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.946750</td>\n",
       "      <td>0.907800</td>\n",
       "      <td>0.915787</td>\n",
       "      <td>0.914977</td>\n",
       "      <td>0.991828</td>\n",
       "      <td>0.995905</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006884</td>\n",
       "      <td>0.002765</td>\n",
       "      <td>0.001389</td>\n",
       "      <td>0.011789</td>\n",
       "      <td>0.012027</td>\n",
       "      <td>0.003910</td>\n",
       "      <td>0.003910</td>\n",
       "      <td>0.000678</td>\n",
       "      <td>0.000676</td>\n",
       "      <td>0.958722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>xgboost_default_StratifiedGroupKFold</td>\n",
       "      <td>level_2</td>\n",
       "      <td>0.938819</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.938269</td>\n",
       "      <td>0.905050</td>\n",
       "      <td>0.912231</td>\n",
       "      <td>0.911607</td>\n",
       "      <td>0.995858</td>\n",
       "      <td>0.997927</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006161</td>\n",
       "      <td>0.001860</td>\n",
       "      <td>0.000932</td>\n",
       "      <td>0.010951</td>\n",
       "      <td>0.010503</td>\n",
       "      <td>0.003531</td>\n",
       "      <td>0.003531</td>\n",
       "      <td>0.000628</td>\n",
       "      <td>0.000626</td>\n",
       "      <td>0.959776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>xgboost_default_StratifiedGroupKFold</td>\n",
       "      <td>level_3</td>\n",
       "      <td>0.925801</td>\n",
       "      <td>0.936042</td>\n",
       "      <td>0.924738</td>\n",
       "      <td>0.883379</td>\n",
       "      <td>0.901992</td>\n",
       "      <td>0.901470</td>\n",
       "      <td>0.999103</td>\n",
       "      <td>0.999552</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005228</td>\n",
       "      <td>0.000287</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>0.010562</td>\n",
       "      <td>0.006439</td>\n",
       "      <td>0.002845</td>\n",
       "      <td>0.002845</td>\n",
       "      <td>0.000597</td>\n",
       "      <td>0.000593</td>\n",
       "      <td>0.963755</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>87 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  method    level  f1_weighted_mean  \\\n",
       "0                          celllens_LITE  level_1          0.788653   \n",
       "1                          celllens_LITE  level_2          0.755216   \n",
       "2                          celllens_LITE  level_3          0.659848   \n",
       "3                          celllens_full  level_1          0.766359   \n",
       "4                          celllens_full  level_2          0.709971   \n",
       "..                                   ...      ...               ...   \n",
       "82                                tribus  level_2          0.703929   \n",
       "83                                tribus  level_3          0.633979   \n",
       "84  xgboost_default_StratifiedGroupKFold  level_1          0.947002   \n",
       "85  xgboost_default_StratifiedGroupKFold  level_2          0.938819   \n",
       "86  xgboost_default_StratifiedGroupKFold  level_3          0.925801   \n",
       "\n",
       "    hierarchial_f1_mean  accuracy_mean  macro_f1_mean  mcc_mean  kappa_mean  \\\n",
       "0                   NaN       0.803389       0.469044  0.684407    0.679668   \n",
       "1                   NaN       0.777380       0.479881  0.672814    0.668232   \n",
       "2              0.766450       0.698724       0.446223  0.591576    0.586953   \n",
       "3                   NaN       0.775488       0.439271  0.650596    0.641313   \n",
       "4                   NaN       0.733022       0.427790  0.612692    0.604567   \n",
       "..                  ...            ...            ...       ...         ...   \n",
       "82                  NaN       0.695485       0.539610  0.584846    0.572785   \n",
       "83             0.678457       0.597261       0.429557  0.496122    0.488219   \n",
       "84                  NaN       0.946750       0.907800  0.915787    0.914977   \n",
       "85                  NaN       0.938269       0.905050  0.912231    0.911607   \n",
       "86             0.936042       0.924738       0.883379  0.901992    0.901470   \n",
       "\n",
       "     r2_mean  pearson_corr_mean  ...  kappa_std    r2_std  pearson_corr_std  \\\n",
       "0   0.963801           0.981643  ...   0.027585  0.029180          0.014906   \n",
       "1   0.973147           0.986401  ...   0.024798  0.027795          0.014147   \n",
       "2   0.971893           0.985812  ...   0.028483  0.017932          0.009128   \n",
       "3   0.907938           0.952580  ...   0.019974  0.048689          0.025720   \n",
       "4   0.923177           0.960582  ...   0.020131  0.045940          0.023949   \n",
       "..       ...                ...  ...        ...       ...               ...   \n",
       "82  0.739327           0.857539  ...   0.035974  0.117236          0.070298   \n",
       "83  0.870576           0.932585  ...   0.034828  0.060071          0.032814   \n",
       "84  0.991828           0.995905  ...   0.006884  0.002765          0.001389   \n",
       "85  0.995858           0.997927  ...   0.006161  0.001860          0.000932   \n",
       "86  0.999103           0.999552  ...   0.005228  0.000287          0.000144   \n",
       "\n",
       "     ari_std   nmi_std   jsd_std  jsd_scaled_std  kl_divergence_std  \\\n",
       "0   0.031867  0.029341  0.020956        0.020956           0.020155   \n",
       "1   0.022455  0.023145  0.023286        0.023286           0.030208   \n",
       "2   0.022721  0.023710  0.029634        0.029634           0.047499   \n",
       "3   0.017163  0.011848  0.020896        0.020896           0.033841   \n",
       "4   0.026425  0.032952  0.036462        0.036462           0.055323   \n",
       "..       ...       ...       ...             ...                ...   \n",
       "82  0.040377  0.025030  0.022567        0.022567           0.042518   \n",
       "83  0.029950  0.017437  0.027970        0.027970           0.138567   \n",
       "84  0.011789  0.012027  0.003910        0.003910           0.000678   \n",
       "85  0.010951  0.010503  0.003531        0.003531           0.000628   \n",
       "86  0.010562  0.006439  0.002845        0.002845           0.000597   \n",
       "\n",
       "    kl_scaled_std  stability  \n",
       "0        0.017381   0.840763  \n",
       "1        0.024901   0.810616  \n",
       "2        0.033332   0.766545  \n",
       "3        0.027113   0.881787  \n",
       "4        0.042674   0.861932  \n",
       "..            ...        ...  \n",
       "82       0.031922   0.777785  \n",
       "83       0.057350   0.760949  \n",
       "84       0.000676   0.958722  \n",
       "85       0.000626   0.959776  \n",
       "86       0.000593   0.963755  \n",
       "\n",
       "[87 rows x 31 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91ee72c-491b-4dc2-bcf6-798c7bc06063",
   "metadata": {},
   "source": [
    "## Get limited cell type scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "33537659-8683-4639-ac8e-d4e655dc6cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the limited cell types for evaluation\n",
    "limited_cell_types = [\n",
    "    'B_cell', 'CD4+_T_cell', 'CD8+_T_cell', 'Neutrophil', 'Dendritic_cell', 'Treg'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e32f0858-60f0-41a3-887f-74c145198b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics_for_limited(methods, levels, base_path):\n",
    "    all_results = []\n",
    "\n",
    "    for method in tqdm(methods, desc=\"Methods\"):\n",
    "        try:\n",
    "            for level in levels:\n",
    "                print(f\"Processing method: {method}, level: {level}\")\n",
    "                path = os.path.join(base_path, method, \"level3\")\n",
    "                \n",
    "                if os.path.exists(path):\n",
    "                    files = [f for f in os.listdir(path) if f.startswith(\"predictions\") and f.endswith(\".csv\")]\n",
    "                else:\n",
    "                    print(f\"Path {path} does not exist. Skipping...\")\n",
    "                    files = []\n",
    "\n",
    "                for file in files:\n",
    "                    file_path = os.path.join(path, file)\n",
    "                    if not os.path.exists(file_path):\n",
    "                        print(f\"File {file_path} does not exist. Skipping...\")\n",
    "                        continue\n",
    "                    df = pd.read_csv(file_path)\n",
    "\n",
    "                    df = df[df['true_phenotype'].isin(limited_cell_types)]\n",
    "\n",
    "                    fold_name = os.path.splitext(file)[0]\n",
    "                    \n",
    "                    if level == 'level_3':\n",
    "                        true_label = df['true_phenotype']\n",
    "                        predictions = df[\"predicted_phenotype\"]\n",
    "                    else:\n",
    "                        df[f'mapped_{level}_cell_type'] = df['predicted_phenotype'].apply(lambda x: map_predicted_to_levels(x)[f'{level}_cell_type'])\n",
    "                        mask_na = df[f'mapped_{level}_cell_type'].isna()\n",
    "                        df.loc[mask_na, f'mapped_{level}_cell_type'] = df.loc[mask_na, 'predicted_phenotype']\n",
    "\n",
    "                        if f'{level}_cell_type' not in df.columns:\n",
    "                            true_label = df['true_phenotype'].apply(lambda x: map_predicted_to_levels(x)[f'{level}_cell_type'])\n",
    "                        else:\n",
    "                            true_label = df[f'{level}_cell_type']\n",
    "                        \n",
    "                        predictions = df[f'mapped_{level}_cell_type'] \n",
    "\n",
    "                    f1 = f1_score(true_label, predictions, average='weighted')\n",
    "                    accuracy = (true_label == predictions).mean()\n",
    "                    macro_f1 = f1_score(true_label, predictions, average='macro')\n",
    "                    mcc = matthews_corrcoef(true_label, predictions)\n",
    "                    kappa = cohen_kappa_score(true_label, predictions)\n",
    "\n",
    "                    if level == 'level_3':\n",
    "                        ancestor_map = parse_tree_file(\"cell_type_hierarchy.txt\")\n",
    "                        hierarchical_f1 = hierarchical_f1_score(true_label, predictions, ancestor_map)\n",
    "                    else:\n",
    "                        hierarchical_f1 = None\n",
    "                    \n",
    "                    cell_type_distribution = calculate_cell_type_distribution(df, predictions, true_label)\n",
    "                    r2, pearson_corr = calculate_r2_and_pearson(cell_type_distribution)\n",
    "                    ari = adjusted_rand_score(true_label, predictions)\n",
    "                    nmi = normalized_mutual_info_score(true_label, predictions)\n",
    "                    kl_divergence = sum(cell_type_distribution['predicted_percentage'] / 100 * np.log2((cell_type_distribution['predicted_percentage'] + 1e-9) / (cell_type_distribution['true_percentage'] + 1e-9)))\n",
    "                    scaled_kl_mean = 1 / (1 + kl_divergence)\n",
    "                    jensen = jensenshannon(cell_type_distribution['predicted_percentage'] / 100, cell_type_distribution['true_percentage'] / 100, base=2)\n",
    "                    jensen_scaled = 1 - jensen\n",
    "                    g_mean = gmean_score(true_label, predictions)\n",
    "                    \n",
    "                    times_path1 = os.path.join(path, \"fold_times.txt\")\n",
    "                    times_path2 = os.path.join(base_path,method, \"fold_times.txt\")\n",
    "                    if os.path.exists(times_path1):\n",
    "                        average_train_time, average_inference_time = calculate_time(times_path1)\n",
    "                    elif os.path.exists(times_path2):\n",
    "                        average_train_time, average_inference_time = calculate_time(times_path2)\n",
    "                    else:\n",
    "                        average_train_time = None\n",
    "                        average_inference_time = None\n",
    "\n",
    "                    all_results.append({\n",
    "                        'method': method,\n",
    "                        'level': level,\n",
    "                        'fold': fold_name,\n",
    "                        'f1_weighted': f1,\n",
    "                        'hierarchical_f1': hierarchical_f1,\n",
    "                        'accuracy': accuracy,\n",
    "                        'macro_f1': macro_f1,\n",
    "                        'g_mean': g_mean,\n",
    "                        'mcc': mcc,\n",
    "                        'kappa': kappa,\n",
    "                        'r2': r2,\n",
    "                        'pearson_corr': pearson_corr,\n",
    "                        'ari': ari,\n",
    "                        'nmi': nmi,\n",
    "                        'jsd': jensen,\n",
    "                        'jsd_scaled': jensen_scaled,\n",
    "                        'kl_divergence': kl_divergence,\n",
    "                        'kl_scaled': scaled_kl_mean,\n",
    "                        'train_time': average_train_time,\n",
    "                        'inference_time':average_inference_time\n",
    "                    })\n",
    "            print(f\"Finished processing method: {method}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error encountered for method {method}: {e}. Skipping this method.\")\n",
    "            continue\n",
    "\n",
    "    return pd.DataFrame(all_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e34ff463-e03e-425a-a44d-b74068b815dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Methods:   0%|          | 0/35 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing method: phenograph_80, level: level_1\n",
      "Processing method: phenograph_80, level: level_2\n",
      "Processing method: phenograph_80, level: level_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Methods:   3%|▎         | 1/35 [00:54<30:54, 54.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing method: phenograph_80\n",
      "Processing method: maps, level: level_1\n",
      "Processing method: maps, level: level_2\n",
      "Processing method: maps, level: level_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Methods:   6%|▌         | 2/35 [01:31<24:18, 44.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing method: maps\n",
      "Processing method: phenograph_40, level: level_1\n",
      "Processing method: phenograph_40, level: level_2\n",
      "Processing method: phenograph_40, level: level_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Methods:   9%|▊         | 3/35 [02:26<26:07, 48.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing method: phenograph_40\n",
      "Processing method: flowsom_meta_clusters, level: level_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hd/hd_hd/hd_ov296/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:407: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/home/hd/hd_hd/hd_ov296/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:407: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/home/hd/hd_hd/hd_ov296/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:758: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/usr/local/lib64/python3.9/site-packages/numpy/lib/_function_base_impl.py:2914: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  c = cov(x, y, rowvar, dtype=dtype)\n",
      "/usr/local/lib64/python3.9/site-packages/numpy/lib/_function_base_impl.py:2773: RuntimeWarning: divide by zero encountered in divide\n",
      "  c *= np.true_divide(1, fact)\n",
      "/usr/local/lib64/python3.9/site-packages/numpy/lib/_function_base_impl.py:2773: RuntimeWarning: invalid value encountered in multiply\n",
      "  c *= np.true_divide(1, fact)\n",
      "/home/hd/hd_hd/hd_ov296/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:407: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/home/hd/hd_hd/hd_ov296/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:407: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/home/hd/hd_hd/hd_ov296/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:407: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/home/hd/hd_hd/hd_ov296/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:758: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/usr/local/lib64/python3.9/site-packages/numpy/lib/_function_base_impl.py:2914: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  c = cov(x, y, rowvar, dtype=dtype)\n",
      "/usr/local/lib64/python3.9/site-packages/numpy/lib/_function_base_impl.py:2773: RuntimeWarning: divide by zero encountered in divide\n",
      "  c *= np.true_divide(1, fact)\n",
      "/usr/local/lib64/python3.9/site-packages/numpy/lib/_function_base_impl.py:2773: RuntimeWarning: invalid value encountered in multiply\n",
      "  c *= np.true_divide(1, fact)\n",
      "/home/hd/hd_hd/hd_ov296/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:407: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/home/hd/hd_hd/hd_ov296/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:407: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/home/hd/hd_hd/hd_ov296/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:407: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/home/hd/hd_hd/hd_ov296/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:758: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/usr/local/lib64/python3.9/site-packages/numpy/lib/_function_base_impl.py:2914: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  c = cov(x, y, rowvar, dtype=dtype)\n",
      "/usr/local/lib64/python3.9/site-packages/numpy/lib/_function_base_impl.py:2773: RuntimeWarning: divide by zero encountered in divide\n",
      "  c *= np.true_divide(1, fact)\n",
      "/usr/local/lib64/python3.9/site-packages/numpy/lib/_function_base_impl.py:2773: RuntimeWarning: invalid value encountered in multiply\n",
      "  c *= np.true_divide(1, fact)\n",
      "/home/hd/hd_hd/hd_ov296/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:407: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/home/hd/hd_hd/hd_ov296/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:407: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/home/hd/hd_hd/hd_ov296/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:407: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/home/hd/hd_hd/hd_ov296/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:758: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/usr/local/lib64/python3.9/site-packages/numpy/lib/_function_base_impl.py:2914: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  c = cov(x, y, rowvar, dtype=dtype)\n",
      "/usr/local/lib64/python3.9/site-packages/numpy/lib/_function_base_impl.py:2773: RuntimeWarning: divide by zero encountered in divide\n",
      "  c *= np.true_divide(1, fact)\n",
      "/usr/local/lib64/python3.9/site-packages/numpy/lib/_function_base_impl.py:2773: RuntimeWarning: invalid value encountered in multiply\n",
      "  c *= np.true_divide(1, fact)\n",
      "/home/hd/hd_hd/hd_ov296/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:407: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/home/hd/hd_hd/hd_ov296/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:407: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/home/hd/hd_hd/hd_ov296/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:407: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/home/hd/hd_hd/hd_ov296/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:758: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/usr/local/lib64/python3.9/site-packages/numpy/lib/_function_base_impl.py:2914: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  c = cov(x, y, rowvar, dtype=dtype)\n",
      "/usr/local/lib64/python3.9/site-packages/numpy/lib/_function_base_impl.py:2773: RuntimeWarning: divide by zero encountered in divide\n",
      "  c *= np.true_divide(1, fact)\n",
      "/usr/local/lib64/python3.9/site-packages/numpy/lib/_function_base_impl.py:2773: RuntimeWarning: invalid value encountered in multiply\n",
      "  c *= np.true_divide(1, fact)\n",
      "/home/hd/hd_hd/hd_ov296/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:407: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing method: flowsom_meta_clusters, level: level_2\n",
      "Processing method: flowsom_meta_clusters, level: level_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Methods:  11%|█▏        | 4/35 [03:25<27:28, 53.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing method: flowsom_meta_clusters\n",
      "Processing method: CLI_test, level: level_1\n",
      "Path ../results/cHL_2_MIBI/CLI_test/level3 does not exist. Skipping...\n",
      "Processing method: CLI_test, level: level_2\n",
      "Path ../results/cHL_2_MIBI/CLI_test/level3 does not exist. Skipping...\n",
      "Processing method: CLI_test, level: level_3\n",
      "Path ../results/cHL_2_MIBI/CLI_test/level3 does not exist. Skipping...\n",
      "Finished processing method: CLI_test\n",
      "Processing method: scyan, level: level_1\n",
      "Processing method: scyan, level: level_2\n",
      "Processing method: scyan, level: level_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Methods:  17%|█▋        | 6/35 [04:27<19:59, 41.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing method: scyan\n",
      "Processing method: phenograph_20, level: level_1\n",
      "Processing method: phenograph_20, level: level_2\n",
      "Processing method: phenograph_20, level: level_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Methods:  20%|██        | 7/35 [05:22<20:58, 44.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing method: phenograph_20\n",
      "Processing method: tacit, level: level_1\n",
      "Processing method: tacit, level: level_2\n",
      "Processing method: tacit, level: level_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Methods:  23%|██▎       | 8/35 [06:16<21:23, 47.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing method: tacit\n",
      "Processing method: nimbus_phenograph_40, level: level_1\n",
      "Processing method: nimbus_phenograph_40, level: level_2\n",
      "Processing method: nimbus_phenograph_40, level: level_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Methods:  26%|██▌       | 9/35 [07:14<21:54, 50.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing method: nimbus_phenograph_40\n",
      "Processing method: FuseSOM_12, level: level_1\n",
      "Processing method: FuseSOM_12, level: level_2\n",
      "Processing method: FuseSOM_12, level: level_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Methods:  29%|██▊       | 10/35 [08:08<21:32, 51.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing method: FuseSOM_12\n",
      "Processing method: deepcelltypes_adapted, level: level_1\n",
      "Processing method: deepcelltypes_adapted, level: level_2\n",
      "Processing method: deepcelltypes_adapted, level: level_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Methods:  31%|███▏      | 11/35 [09:02<20:54, 52.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing method: deepcelltypes_adapted\n",
      "Processing method: nimbus_FuseSOM_12, level: level_1\n",
      "Processing method: nimbus_FuseSOM_12, level: level_2\n",
      "Processing method: nimbus_FuseSOM_12, level: level_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Methods:  34%|███▍      | 12/35 [10:00<20:39, 53.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing method: nimbus_FuseSOM_12\n",
      "Processing method: .ipynb_checkpoints, level: level_1\n",
      "Path ../results/cHL_2_MIBI/.ipynb_checkpoints/level3 does not exist. Skipping...\n",
      "Processing method: .ipynb_checkpoints, level: level_2\n",
      "Path ../results/cHL_2_MIBI/.ipynb_checkpoints/level3 does not exist. Skipping...\n",
      "Processing method: .ipynb_checkpoints, level: level_3\n",
      "Path ../results/cHL_2_MIBI/.ipynb_checkpoints/level3 does not exist. Skipping...\n",
      "Finished processing method: .ipynb_checkpoints\n",
      "Processing method: cellsighter, level: level_1\n",
      "Processing method: cellsighter, level: level_2\n",
      "Processing method: cellsighter, level: level_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Methods:  40%|████      | 14/35 [10:42<13:38, 39.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing method: cellsighter\n",
      "Processing method: astir, level: level_1\n",
      "Processing method: astir, level: level_2\n",
      "Processing method: astir, level: level_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Methods:  43%|████▎     | 15/35 [11:38<14:22, 43.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing method: astir\n",
      "Processing method: leiden_res0_5, level: level_1\n",
      "Processing method: leiden_res0_5, level: level_2\n",
      "Processing method: leiden_res0_5, level: level_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Methods:  46%|████▌     | 16/35 [12:33<14:36, 46.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing method: leiden_res0_5\n",
      "Processing method: random_forest_default_StratifiedGroupKFold, level: level_1\n",
      "Processing method: random_forest_default_StratifiedGroupKFold, level: level_2\n",
      "Processing method: random_forest_default_StratifiedGroupKFold, level: level_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Methods:  49%|████▊     | 17/35 [13:10<13:04, 43.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing method: random_forest_default_StratifiedGroupKFold\n",
      "Processing method: leiden_res2_0, level: level_1\n",
      "Processing method: leiden_res2_0, level: level_2\n",
      "Processing method: leiden_res2_0, level: level_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Methods:  51%|█████▏    | 18/35 [14:04<13:14, 46.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing method: leiden_res2_0\n",
      "Processing method: nimbus_leiden_0_8, level: level_1\n",
      "Processing method: nimbus_leiden_0_8, level: level_2\n",
      "Processing method: nimbus_leiden_0_8, level: level_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Methods:  54%|█████▍    | 19/35 [15:02<13:15, 49.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing method: nimbus_leiden_0_8\n",
      "Processing method: nimbus, level: level_1\n",
      "Path ../results/cHL_2_MIBI/nimbus/level3 does not exist. Skipping...\n",
      "Processing method: nimbus, level: level_2\n",
      "Path ../results/cHL_2_MIBI/nimbus/level3 does not exist. Skipping...\n",
      "Processing method: nimbus, level: level_3\n",
      "Path ../results/cHL_2_MIBI/nimbus/level3 does not exist. Skipping...\n",
      "Finished processing method: nimbus\n",
      "Processing method: most_frequent_default_StratifiedGroupKFold, level: level_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hd/hd_hd/hd_ov296/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:407: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/home/hd/hd_hd/hd_ov296/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:407: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/home/hd/hd_hd/hd_ov296/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:758: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/usr/local/lib64/python3.9/site-packages/numpy/lib/_function_base_impl.py:2914: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  c = cov(x, y, rowvar, dtype=dtype)\n",
      "/usr/local/lib64/python3.9/site-packages/numpy/lib/_function_base_impl.py:2773: RuntimeWarning: divide by zero encountered in divide\n",
      "  c *= np.true_divide(1, fact)\n",
      "/usr/local/lib64/python3.9/site-packages/numpy/lib/_function_base_impl.py:2773: RuntimeWarning: invalid value encountered in multiply\n",
      "  c *= np.true_divide(1, fact)\n",
      "/home/hd/hd_hd/hd_ov296/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:407: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/home/hd/hd_hd/hd_ov296/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:407: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/home/hd/hd_hd/hd_ov296/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:407: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/home/hd/hd_hd/hd_ov296/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:758: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/usr/local/lib64/python3.9/site-packages/numpy/lib/_function_base_impl.py:2914: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  c = cov(x, y, rowvar, dtype=dtype)\n",
      "/usr/local/lib64/python3.9/site-packages/numpy/lib/_function_base_impl.py:2773: RuntimeWarning: divide by zero encountered in divide\n",
      "  c *= np.true_divide(1, fact)\n",
      "/usr/local/lib64/python3.9/site-packages/numpy/lib/_function_base_impl.py:2773: RuntimeWarning: invalid value encountered in multiply\n",
      "  c *= np.true_divide(1, fact)\n",
      "/home/hd/hd_hd/hd_ov296/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:407: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/home/hd/hd_hd/hd_ov296/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:407: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/home/hd/hd_hd/hd_ov296/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:407: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/home/hd/hd_hd/hd_ov296/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:758: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/usr/local/lib64/python3.9/site-packages/numpy/lib/_function_base_impl.py:2914: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  c = cov(x, y, rowvar, dtype=dtype)\n",
      "/usr/local/lib64/python3.9/site-packages/numpy/lib/_function_base_impl.py:2773: RuntimeWarning: divide by zero encountered in divide\n",
      "  c *= np.true_divide(1, fact)\n",
      "/usr/local/lib64/python3.9/site-packages/numpy/lib/_function_base_impl.py:2773: RuntimeWarning: invalid value encountered in multiply\n",
      "  c *= np.true_divide(1, fact)\n",
      "/home/hd/hd_hd/hd_ov296/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:407: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/home/hd/hd_hd/hd_ov296/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:407: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/home/hd/hd_hd/hd_ov296/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:407: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/home/hd/hd_hd/hd_ov296/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:758: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/usr/local/lib64/python3.9/site-packages/numpy/lib/_function_base_impl.py:2914: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  c = cov(x, y, rowvar, dtype=dtype)\n",
      "/usr/local/lib64/python3.9/site-packages/numpy/lib/_function_base_impl.py:2773: RuntimeWarning: divide by zero encountered in divide\n",
      "  c *= np.true_divide(1, fact)\n",
      "/usr/local/lib64/python3.9/site-packages/numpy/lib/_function_base_impl.py:2773: RuntimeWarning: invalid value encountered in multiply\n",
      "  c *= np.true_divide(1, fact)\n",
      "/home/hd/hd_hd/hd_ov296/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:407: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/home/hd/hd_hd/hd_ov296/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:407: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/home/hd/hd_hd/hd_ov296/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:407: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/home/hd/hd_hd/hd_ov296/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:758: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/usr/local/lib64/python3.9/site-packages/numpy/lib/_function_base_impl.py:2914: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  c = cov(x, y, rowvar, dtype=dtype)\n",
      "/usr/local/lib64/python3.9/site-packages/numpy/lib/_function_base_impl.py:2773: RuntimeWarning: divide by zero encountered in divide\n",
      "  c *= np.true_divide(1, fact)\n",
      "/usr/local/lib64/python3.9/site-packages/numpy/lib/_function_base_impl.py:2773: RuntimeWarning: invalid value encountered in multiply\n",
      "  c *= np.true_divide(1, fact)\n",
      "/home/hd/hd_hd/hd_ov296/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:407: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing method: most_frequent_default_StratifiedGroupKFold, level: level_2\n",
      "Processing method: most_frequent_default_StratifiedGroupKFold, level: level_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Methods:  60%|██████    | 21/35 [15:40<08:23, 35.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error encountered for method most_frequent_default_StratifiedGroupKFold: division by zero. Skipping this method.\n",
      "Processing method: flowsom, level: level_1\n",
      "Processing method: flowsom, level: level_2\n",
      "Processing method: flowsom, level: level_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Methods:  63%|██████▎   | 22/35 [16:34<08:46, 40.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing method: flowsom\n",
      "Processing method: stratified_default_StratifiedGroupKFold, level: level_1\n",
      "Processing method: stratified_default_StratifiedGroupKFold, level: level_2\n",
      "Processing method: stratified_default_StratifiedGroupKFold, level: level_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Methods:  66%|██████▌   | 23/35 [17:11<07:54, 39.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing method: stratified_default_StratifiedGroupKFold\n",
      "Processing method: leiden_res1_0, level: level_1\n",
      "Processing method: leiden_res1_0, level: level_2\n",
      "Processing method: leiden_res1_0, level: level_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Methods:  69%|██████▊   | 24/35 [18:06<08:01, 43.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing method: leiden_res1_0\n",
      "Processing method: xgboost_default_StratifiedGroupKFold, level: level_1\n",
      "Processing method: xgboost_default_StratifiedGroupKFold, level: level_2\n",
      "Processing method: xgboost_default_StratifiedGroupKFold, level: level_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Methods:  71%|███████▏  | 25/35 [18:43<06:58, 41.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing method: xgboost_default_StratifiedGroupKFold\n",
      "Processing method: ribca_adapted, level: level_1\n",
      "Processing method: ribca_adapted, level: level_2\n",
      "Processing method: ribca_adapted, level: level_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Methods:  74%|███████▍  | 26/35 [19:38<06:48, 45.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing method: ribca_adapted\n",
      "Processing method: leiden_res0_8, level: level_1\n",
      "Processing method: leiden_res0_8, level: level_2\n",
      "Processing method: leiden_res0_8, level: level_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Methods:  77%|███████▋  | 27/35 [20:33<06:25, 48.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing method: leiden_res0_8\n",
      "Processing method: tribus, level: level_1\n",
      "Processing method: tribus, level: level_2\n",
      "Processing method: tribus, level: level_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Methods:  80%|████████  | 28/35 [21:27<05:49, 49.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing method: tribus\n",
      "Processing method: phenograph_30, level: level_1\n",
      "Processing method: phenograph_30, level: level_2\n",
      "Processing method: phenograph_30, level: level_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Methods:  83%|████████▎ | 29/35 [22:22<05:08, 51.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing method: phenograph_30\n",
      "Processing method: celllens_full, level: level_1\n",
      "Processing method: celllens_full, level: level_2\n",
      "Processing method: celllens_full, level: level_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Methods:  86%|████████▌ | 30/35 [23:18<04:24, 52.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing method: celllens_full\n",
      "Processing method: logistic_regression_default_StratifiedGroupKFold, level: level_1\n",
      "Processing method: logistic_regression_default_StratifiedGroupKFold, level: level_2\n",
      "Processing method: logistic_regression_default_StratifiedGroupKFold, level: level_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Methods:  89%|████████▊ | 31/35 [23:55<03:12, 48.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing method: logistic_regression_default_StratifiedGroupKFold\n",
      "Processing method: deepcelltypes, level: level_1\n",
      "Processing method: deepcelltypes, level: level_2\n",
      "Processing method: deepcelltypes, level: level_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Methods:  91%|█████████▏| 32/35 [24:49<02:29, 49.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing method: deepcelltypes\n",
      "Processing method: nimbus_flowsom, level: level_1\n",
      "Processing method: nimbus_flowsom, level: level_2\n",
      "Processing method: nimbus_flowsom, level: level_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Methods:  94%|█████████▍| 33/35 [25:47<01:44, 52.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing method: nimbus_flowsom\n",
      "Processing method: ribca, level: level_1\n",
      "Processing method: ribca, level: level_2\n",
      "Processing method: ribca, level: level_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Methods:  97%|█████████▋| 34/35 [26:42<00:53, 53.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing method: ribca\n",
      "Processing method: CellLENS_Lite, level: level_1\n",
      "Processing method: CellLENS_Lite, level: level_2\n",
      "Processing method: CellLENS_Lite, level: level_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Methods: 100%|██████████| 35/35 [27:36<00:00, 47.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing method: CellLENS_Lite\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# minimal cell types results\n",
    "base_path = \"../results/cHL_2_MIBI\"\n",
    "levels = ['level_1', 'level_2', 'level_3']\n",
    "\n",
    "#make a list of folders in the base_path\n",
    "methods = [f for f in os.listdir(base_path) if os.path.isdir(os.path.join(base_path, f))]\n",
    "# Calculate metrics for all methods and levels\n",
    "results = calculate_metrics_for_limited(methods, levels, base_path)\n",
    "# Get the average of the metrics for each method and level, excluding the 'fold' column\n",
    "average_results = results.drop(columns=[\"fold\"]).groupby(['method', 'level'], as_index=False).mean()\n",
    "# Get the standard deviation of the metrics for each method and level\n",
    "std_results = results.drop(columns=[\"fold\"]).groupby(['method', 'level']).std().reset_index()\n",
    "# Merge the average and standard deviation results\n",
    "final_results = pd.merge(average_results, std_results, on=['method', 'level'], suffixes=('_mean', '_std'))\n",
    "\n",
    "# # Rename the columns for clarity\n",
    "# final_results.columns = ['method', 'level', 'f1_weighted_mean', 'hierarchial_f1_mean', 'accuracy_mean', 'macro_f1_mean', \n",
    "#                          'mcc_mean', 'kappa_mean', 'r2_mean', 'pearson_corr_mean', 'ari_mean', 'nmi_mean',\n",
    "#                          'jsd_mean', 'jsd_scaled_mean', 'kl_divergence_mean', 'kl_scaled_mean',\n",
    "#                           'f1_weighted_std', 'hierarchial_f1_std','accuracy_std', 'macro_f1_std', \n",
    "#                           'mcc_std', 'kappa_std', 'r2_std', 'pearson_corr_std', 'ari_std', 'nmi_std',\n",
    "#                           'jsd_std', 'jsd_scaled_std', 'kl_divergence_std', 'kl_scaled_std']\n",
    "\n",
    "# calculate a stability metric for the methods where s = (1 - std/stability_thresh)\n",
    "stability_thresh = 0.2\n",
    "final_results['stability'] = 1 - (final_results['f1_weighted_std'] / stability_thresh)\n",
    "# set to 0 if negative\n",
    "final_results.loc[final_results['stability'] < 0, 'stability'] = 0\n",
    "\n",
    "# Save the final results to a CSV file with ';' as the separator\n",
    "final_results.to_csv(os.path.join(base_path, \"minimal_results.csv\"), index=False, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa45d0e-4a4f-46bd-bf88-f899b121507b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e9e29415-f80f-402b-843a-b6698534232f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Get the hierarchy mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5bc67f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Macrophage': {'level_2_cell_type': 'Myeloid_immune',\n",
       "  'level_1_cell_type': 'Immune'},\n",
       " 'Plasma_cell': {'level_2_cell_type': 'Lymphoid_immune',\n",
       "  'level_1_cell_type': 'Immune'},\n",
       " 'Neutrophil': {'level_2_cell_type': 'Myeloid_immune',\n",
       "  'level_1_cell_type': 'Immune'},\n",
       " 'Adipocyte': {'level_2_cell_type': 'Adipocyte',\n",
       "  'level_1_cell_type': 'Stromal'},\n",
       " 'CD8+_T_cell': {'level_2_cell_type': 'Lymphoid_immune',\n",
       "  'level_1_cell_type': 'Immune'},\n",
       " 'Endothelial': {'level_2_cell_type': 'Vascular',\n",
       "  'level_1_cell_type': 'Stromal'},\n",
       " 'CD4+_T_cell': {'level_2_cell_type': 'Lymphoid_immune',\n",
       "  'level_1_cell_type': 'Immune'},\n",
       " 'undefined': {'level_2_cell_type': 'undefined',\n",
       "  'level_1_cell_type': 'undefined'},\n",
       " 'Osteoblast': {'level_2_cell_type': 'Bone', 'level_1_cell_type': 'Stromal'},\n",
       " 'HSCs': {'level_2_cell_type': 'HSCs', 'level_1_cell_type': 'HSCs'},\n",
       " 'Osteocyte': {'level_2_cell_type': 'Bone', 'level_1_cell_type': 'Stromal'},\n",
       " 'Dendritic_cell': {'level_2_cell_type': 'Myeloid_immune',\n",
       "  'level_1_cell_type': 'Immune'},\n",
       " 'Osteoclast': {'level_2_cell_type': 'Bone', 'level_1_cell_type': 'Stromal'},\n",
       " 'B_cell': {'level_2_cell_type': 'Lymphoid_immune',\n",
       "  'level_1_cell_type': 'Immune'},\n",
       " 'NK_cell': {'level_2_cell_type': 'Lymphoid_immune',\n",
       "  'level_1_cell_type': 'Immune'},\n",
       " 'Monocyte': {'level_2_cell_type': 'Myeloid_immune',\n",
       "  'level_1_cell_type': 'Immune'},\n",
       " 'Lymphatic': {'level_2_cell_type': 'Vascular',\n",
       "  'level_1_cell_type': 'Stromal'},\n",
       " 'M1_Macrophage': {'level_2_cell_type': 'Myeloid_immune',\n",
       "  'level_1_cell_type': 'Immune'},\n",
       " 'Seg Artifact': {'level_2_cell_type': 'Seg Artifact',\n",
       "  'level_1_cell_type': 'Seg Artifact'},\n",
       " 'Mast_cell': {'level_2_cell_type': 'Myeloid_immune',\n",
       "  'level_1_cell_type': 'Immune'},\n",
       " 'Cancer': {'level_2_cell_type': 'Cancer', 'level_1_cell_type': 'Cancer'},\n",
       " 'M2_Macrophage': {'level_2_cell_type': 'Myeloid_immune',\n",
       "  'level_1_cell_type': 'Immune'},\n",
       " 'Treg': {'level_2_cell_type': 'Lymphoid_immune',\n",
       "  'level_1_cell_type': 'Immune'},\n",
       " 'Cytotoxic_CD8+_T_cell': {'level_2_cell_type': 'Lymphoid_immune',\n",
       "  'level_1_cell_type': 'Immune'},\n",
       " 'Epithelial': {'level_2_cell_type': 'Epithelial',\n",
       "  'level_1_cell_type': 'Epithelial'},\n",
       " 'unedfined': {'level_2_cell_type': 'unedfined',\n",
       "  'level_1_cell_type': 'unedfined'},\n",
       " 'Artifact': {'level_2_cell_type': 'Artifact',\n",
       "  'level_1_cell_type': 'Artifact'},\n",
       " 'Early Myeloid Progenitor': {'level_2_cell_type': 'Myeloid_progenitor',\n",
       "  'level_1_cell_type': 'Progenitor'},\n",
       " 'Mature Myeloid': {'level_2_cell_type': 'Myeloid_immune',\n",
       "  'level_1_cell_type': 'Immune'},\n",
       " 'Intermediate Myeloid': {'level_2_cell_type': 'Myeloid_progenitor',\n",
       "  'level_1_cell_type': 'Progenitor'},\n",
       " 'B_cells': {'level_2_cell_type': 'Lymphoid_immune',\n",
       "  'level_1_cell_type': 'Immune'},\n",
       " 'Endosteal': {'level_2_cell_type': 'Endosteal',\n",
       "  'level_1_cell_type': 'Endosteal'},\n",
       " 'SEC': {'level_2_cell_type': 'Vascular', 'level_1_cell_type': 'Stromal'},\n",
       " 'Erythroid': {'level_2_cell_type': 'Erythroid_mk_progenitor',\n",
       "  'level_1_cell_type': 'Progenitor'},\n",
       " 'Autofluorescent': {'level_2_cell_type': 'Autofluorescent',\n",
       "  'level_1_cell_type': 'Autofluorescent'},\n",
       " 'Non-classical_Monocyte': {'level_2_cell_type': 'Myeloid_immune',\n",
       "  'level_1_cell_type': 'Immune'},\n",
       " 'CD44+ Undetermined': {'level_2_cell_type': 'CD44+ Undetermined',\n",
       "  'level_1_cell_type': 'undefined'},\n",
       " 'GATA1neg_Mks': {'level_2_cell_type': 'GATA1neg_Mks',\n",
       "  'level_1_cell_type': 'Megakaryocytes'},\n",
       " 'SPINK2+ HSPC': {'level_2_cell_type': 'SPINK2+ HSPC',\n",
       "  'level_1_cell_type': 'Progenitor'},\n",
       " 'HSPC': {'level_2_cell_type': 'HSPC', 'level_1_cell_type': 'Progenitor'},\n",
       " 'Adipo-MSC': {'level_2_cell_type': 'Mesenchymal_stem',\n",
       "  'level_1_cell_type': 'Progenitor'},\n",
       " 'AEC': {'level_2_cell_type': 'Vascular', 'level_1_cell_type': 'Stromal'},\n",
       " 'THY1+ MSC': {'level_2_cell_type': 'Mesenchymal_stem',\n",
       "  'level_1_cell_type': 'Progenitor'},\n",
       " 'Erythroblast': {'level_2_cell_type': 'Erythroid_mk_progenitor',\n",
       "  'level_1_cell_type': 'Progenitor'},\n",
       " 'Plasmacytoid_dendritic_cell': {'level_2_cell_type': 'Myeloid_immune',\n",
       "  'level_1_cell_type': 'Immune'},\n",
       " 'MEP/Early Erythroblast': {'level_2_cell_type': 'Erythroid_mk_progenitor',\n",
       "  'level_1_cell_type': 'Progenitor'},\n",
       " 'Immature_B_cell': {'level_2_cell_type': 'Lymphoid_immune',\n",
       "  'level_1_cell_type': 'Immune'},\n",
       " 'GMP/Myeloblast': {'level_2_cell_type': 'Myeloid_progenitor',\n",
       "  'level_1_cell_type': 'Progenitor'},\n",
       " 'HSC': {'level_2_cell_type': 'HSC', 'level_1_cell_type': 'Progenitor'},\n",
       " 'VSMC': {'level_2_cell_type': 'Vascular', 'level_1_cell_type': 'Stromal'},\n",
       " 'CLP': {'level_2_cell_type': 'Lymphoid_progenitor',\n",
       "  'level_1_cell_type': 'Progenitor'},\n",
       " 'GATA1pos_Mks': {'level_2_cell_type': 'GATA1pos_Mks',\n",
       "  'level_1_cell_type': 'Megakaryocytes'},\n",
       " 'CD34+ CD61+': {'level_2_cell_type': 'CD34+ CD61+',\n",
       "  'level_1_cell_type': 'undefined'},\n",
       " 'GMP': {'level_2_cell_type': 'Myeloid_progenitor',\n",
       "  'level_1_cell_type': 'Progenitor'},\n",
       " 'Schwann Cells': {'level_2_cell_type': 'Schwann Cells',\n",
       "  'level_1_cell_type': 'Neuronal'},\n",
       " 'Myeloid': {'level_2_cell_type': 'Myeloid_immune',\n",
       "  'level_1_cell_type': 'Immune'},\n",
       " 'CD4_Treg': {'level_2_cell_type': 'Lymphoid_immune',\n",
       "  'level_1_cell_type': 'Immune'},\n",
       " 'CD8_Treg': {'level_2_cell_type': 'Lymphoid_immune',\n",
       "  'level_1_cell_type': 'Immune'},\n",
       " 'ki67_CD4': {'level_2_cell_type': 'Lymphoid_immune',\n",
       "  'level_1_cell_type': 'Immune'},\n",
       " 'ki67_CD8': {'level_2_cell_type': 'Lymphoid_immune',\n",
       "  'level_1_cell_type': 'Immune'},\n",
       " 'CD8_CXCL13': {'level_2_cell_type': 'Lymphoid_immune',\n",
       "  'level_1_cell_type': 'Immune'},\n",
       " 'CD4_CXCL13': {'level_2_cell_type': 'Lymphoid_immune',\n",
       "  'level_1_cell_type': 'Immune'},\n",
       " 'IDO_CD4': {'level_2_cell_type': 'Lymphoid_immune',\n",
       "  'level_1_cell_type': 'Immune'},\n",
       " 'IDO_CD8': {'level_2_cell_type': 'Lymphoid_immune',\n",
       "  'level_1_cell_type': 'Immune'},\n",
       " 'T_cell': {'level_2_cell_type': 'Lymphoid_immune',\n",
       "  'level_1_cell_type': 'Immune'},\n",
       " 'Vimentin high': {'level_2_cell_type': 'Vimentin high',\n",
       "  'level_1_cell_type': 'Stromal'},\n",
       " 'SMA+_Fibroblast': {'level_2_cell_type': 'Fibroblast',\n",
       "  'level_1_cell_type': 'Stromal'},\n",
       " 'CD10_CAF': {'level_2_cell_type': 'Fibroblast',\n",
       "  'level_1_cell_type': 'Stromal'},\n",
       " 'FN_Cdh11_mCAF': {'level_2_cell_type': 'Fibroblast',\n",
       "  'level_1_cell_type': 'Stromal'},\n",
       " 'Fibroblast': {'level_2_cell_type': 'Fibroblast',\n",
       "  'level_1_cell_type': 'Stromal'},\n",
       " 'vCAF': {'level_2_cell_type': 'Fibroblast', 'level_1_cell_type': 'Stromal'},\n",
       " 'CXCL13_CAF': {'level_2_cell_type': 'Fibroblast',\n",
       "  'level_1_cell_type': 'Stromal'},\n",
       " 'CD73_CAF': {'level_2_cell_type': 'Fibroblast',\n",
       "  'level_1_cell_type': 'Stromal'},\n",
       " 'CCL21_CAF': {'level_2_cell_type': 'Fibroblast',\n",
       "  'level_1_cell_type': 'Stromal'},\n",
       " 'IDO_CAF': {'level_2_cell_type': 'Fibroblast',\n",
       "  'level_1_cell_type': 'Stromal'},\n",
       " 'CD34_CAF': {'level_2_cell_type': 'Fibroblast',\n",
       "  'level_1_cell_type': 'Stromal'},\n",
       " 'hypoxia': {'level_2_cell_type': 'hypoxia', 'level_1_cell_type': 'hypoxia'},\n",
       " 'CA9_CD10_CAF': {'level_2_cell_type': 'Fibroblast',\n",
       "  'level_1_cell_type': 'Stromal'},\n",
       " 'hypoxic Cancer': {'level_2_cell_type': 'hypoxic Cancer',\n",
       "  'level_1_cell_type': 'Cancer'},\n",
       " 'Blood': {'level_2_cell_type': 'Vascular', 'level_1_cell_type': 'Stromal'},\n",
       " 'HEV': {'level_2_cell_type': 'Vascular', 'level_1_cell_type': 'Stromal'},\n",
       " 'Cytotoxic_CD4+_T_cell': {'level_2_cell_type': 'Lymphoid_immune',\n",
       "  'level_1_cell_type': 'Immune'},\n",
       " 'Stroma': {'level_2_cell_type': 'Stroma', 'level_1_cell_type': 'Stromal'},\n",
       " 'HLADR': {'level_2_cell_type': 'HLADR', 'level_1_cell_type': 'HLADR'},\n",
       " 'BnT': {'level_2_cell_type': 'Lymphoid_immune',\n",
       "  'level_1_cell_type': 'Immune'},\n",
       " 'M2a_Macrophage': {'level_2_cell_type': 'Myeloid_immune',\n",
       "  'level_1_cell_type': 'Immune'},\n",
       " 'NK1': {'level_2_cell_type': 'Lymphoid_immune',\n",
       "  'level_1_cell_type': 'Immune'},\n",
       " 'NK_T_cell': {'level_2_cell_type': 'Lymphoid_immune',\n",
       "  'level_1_cell_type': 'Immune'},\n",
       " 'Myofibroblasts': {'level_2_cell_type': 'Myofibroblasts',\n",
       "  'level_1_cell_type': 'Stromal'},\n",
       " 'M1a_Macrophage': {'level_2_cell_type': 'Myeloid_immune',\n",
       "  'level_1_cell_type': 'Immune'},\n",
       " 'EVT1a': {'level_2_cell_type': 'Trophoblast',\n",
       "  'level_1_cell_type': 'Trophoblast'},\n",
       " 'M1b_Macrophage': {'level_2_cell_type': 'Myeloid_immune',\n",
       "  'level_1_cell_type': 'Immune'},\n",
       " 'EVT1b': {'level_2_cell_type': 'Trophoblast',\n",
       "  'level_1_cell_type': 'Trophoblast'},\n",
       " 'M2c_Macrophage': {'level_2_cell_type': 'Myeloid_immune',\n",
       "  'level_1_cell_type': 'Immune'},\n",
       " 'NK2': {'level_2_cell_type': 'Lymphoid_immune',\n",
       "  'level_1_cell_type': 'Immune'},\n",
       " 'muscle': {'level_2_cell_type': 'muscle', 'level_1_cell_type': 'Stromal'},\n",
       " 'NK3': {'level_2_cell_type': 'Lymphoid_immune',\n",
       "  'level_1_cell_type': 'Immune'},\n",
       " 'EVT2': {'level_2_cell_type': 'Trophoblast',\n",
       "  'level_1_cell_type': 'Trophoblast'},\n",
       " 'M2b_Macrophage': {'level_2_cell_type': 'Myeloid_immune',\n",
       "  'level_1_cell_type': 'Immune'},\n",
       " 'Glandular': {'level_2_cell_type': 'Glandular',\n",
       "  'level_1_cell_type': 'Stromal'},\n",
       " 'EVT1c': {'level_2_cell_type': 'Trophoblast',\n",
       "  'level_1_cell_type': 'Trophoblast'},\n",
       " 'Placental_Mac': {'level_2_cell_type': 'Myeloid_immune',\n",
       "  'level_1_cell_type': 'Immune'},\n",
       " 'NK4': {'level_2_cell_type': 'Lymphoid_immune',\n",
       "  'level_1_cell_type': 'Immune'}}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the hierarchy mappings from the qt files\n",
    "qt_path = \"../data/all_qt\"\n",
    "#read all csv files in the qt_path\n",
    "qt_files = [f for f in os.listdir(qt_path) if f.endswith('.csv')]\n",
    "hierarchy_mappings = {}\n",
    "\n",
    "for qt_file in qt_files:\n",
    "    qt_df = pd.read_csv(os.path.join(qt_path, qt_file))\n",
    "    # Create a hierarchical mapping from cell_type to level_2 and level_1 for this file\n",
    "    mapping = qt_df.drop_duplicates(subset=['cell_type', 'level_2_cell_type', 'level_1_cell_type'])[\n",
    "        ['cell_type', 'level_2_cell_type', 'level_1_cell_type']\n",
    "    ].set_index('cell_type').to_dict(orient='index')\n",
    "    # Update the global mapping without including the qt file name\n",
    "    hierarchy_mappings.update(mapping)\n",
    "\n",
    "# Remove duplicate cell types in the hierarchy_mappings (if any)\n",
    "unique_cell_types = set()\n",
    "for cell_type in list(hierarchy_mappings.keys()):\n",
    "    if cell_type not in unique_cell_types:\n",
    "        unique_cell_types.add(cell_type)\n",
    "    else:\n",
    "        del hierarchy_mappings[cell_type]\n",
    "\n",
    "#save the hierarchy mappings to a file\n",
    "with open('hierarchy_mappings.pkl', 'wb') as f:\n",
    "    import pickle\n",
    "    pickle.dump(hierarchy_mappings, f)\n",
    "\n",
    "#read the hierarchy mappings from the file\n",
    "with open('hierarchy_mappings.pkl', 'rb') as f:\n",
    "    import pickle\n",
    "    hierarchy_mappings = pickle.load(f)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbda1cf-b5a2-4bb1-b8b9-e65ed2387326",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a hierarchical mapping from true_phenotype to level_2 and level_1\n",
    "hierarchy_mapping = pred.drop_duplicates(subset=['true_phenotype', 'level_2_cell_type', 'level_1_cell_type'])[\n",
    "    ['true_phenotype', 'level_2_cell_type', 'level_1_cell_type']\n",
    "].set_index('true_phenotype').to_dict(orient='index')\n",
    "\n",
    "# Example usage: get level_2 and level_1 for a predicted phenotype\n",
    "def map_predicted_to_levels(predicted_phenotype):\n",
    "    return hierarchy_mappings.get(predicted_phenotype, {'level_2_cell_type': None, 'level_1_cell_type': None})\n",
    "\n",
    "# Apply the mapping to the predicted phenotypes\n",
    "pred['mapped_level_2_cell_type'] = pred['predicted_phenotype'].apply(lambda x: map_predicted_to_levels(x)['level_2_cell_type'])\n",
    "pred['mapped_level_1_cell_type'] = pred['predicted_phenotype'].apply(lambda x: map_predicted_to_levels(x)['level_1_cell_type'])\n",
    "\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122618de",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3dd84014",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CD4+_T_cell': {'level_2_cell_type': 'Lymphoid_immune',\n",
       "  'level_1_cell_type': 'Immune'},\n",
       " 'unedfined': {'level_2_cell_type': 'unedfined',\n",
       "  'level_1_cell_type': 'unedfined'},\n",
       " 'Dendritic_cell': {'level_2_cell_type': 'Myeloid_immune',\n",
       "  'level_1_cell_type': 'Immune'},\n",
       " 'CD8+_T_cell': {'level_2_cell_type': 'Lymphoid_immune',\n",
       "  'level_1_cell_type': 'Immune'},\n",
       " 'M2_Macrophage': {'level_2_cell_type': 'Myeloid_immune',\n",
       "  'level_1_cell_type': 'Immune'},\n",
       " 'B_cell': {'level_2_cell_type': 'Lymphoid_immune',\n",
       "  'level_1_cell_type': 'Immune'},\n",
       " 'Treg': {'level_2_cell_type': 'Lymphoid_immune',\n",
       "  'level_1_cell_type': 'Immune'},\n",
       " 'Endothelial': {'level_2_cell_type': 'Vascular',\n",
       "  'level_1_cell_type': 'Stromal'},\n",
       " 'M1_Macrophage': {'level_2_cell_type': 'Myeloid_immune',\n",
       "  'level_1_cell_type': 'Immune'},\n",
       " 'Cancer': {'level_2_cell_type': 'Cancer', 'level_1_cell_type': 'Cancer'},\n",
       " 'Neutrophil': {'level_2_cell_type': 'Myeloid_immune',\n",
       "  'level_1_cell_type': 'Immune'},\n",
       " 'NK_cell': {'level_2_cell_type': 'Lymphoid_immune',\n",
       "  'level_1_cell_type': 'Immune'}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hierarchy_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "49975e06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Immune\n",
      "\tMyeloid_immune\n",
      "\t\tMacrophage\n",
      "\t\tNeutrophil\n",
      "\t\tDendritic_cell\n",
      "\t\tMonocyte\n",
      "\t\tM1_Macrophage\n",
      "\t\tMast_cell\n",
      "\t\tM2_Macrophage\n",
      "\t\tMature Myeloid\n",
      "\t\tNon-classical_Monocyte\n",
      "\t\tPlasmacytoid_dendritic_cell\n",
      "\t\tMyeloid\n",
      "\t\tM2a_Macrophage\n",
      "\t\tM1a_Macrophage\n",
      "\t\tM1b_Macrophage\n",
      "\t\tM2c_Macrophage\n",
      "\t\tM2b_Macrophage\n",
      "\t\tPlacental_Mac\n",
      "\tLymphoid_immune\n",
      "\t\tPlasma_cell\n",
      "\t\tCD8+_T_cell\n",
      "\t\tCD4+_T_cell\n",
      "\t\tB_cell\n",
      "\t\tNK_cell\n",
      "\t\tTreg\n",
      "\t\tCytotoxic_CD8+_T_cell\n",
      "\t\tB_cells\n",
      "\t\tImmature_B_cell\n",
      "\t\tCD4_Treg\n",
      "\t\tCD8_Treg\n",
      "\t\tki67_CD4\n",
      "\t\tki67_CD8\n",
      "\t\tCD8_CXCL13\n",
      "\t\tCD4_CXCL13\n",
      "\t\tIDO_CD4\n",
      "\t\tIDO_CD8\n",
      "\t\tT_cell\n",
      "\t\tCytotoxic_CD4+_T_cell\n",
      "\t\tBnT\n",
      "\t\tNK1\n",
      "\t\tNK_T_cell\n",
      "\t\tNK2\n",
      "\t\tNK3\n",
      "\t\tNK4\n",
      "Stromal\n",
      "\tAdipocyte\n",
      "\t\tAdipocyte\n",
      "\tVascular\n",
      "\t\tEndothelial\n",
      "\t\tLymphatic\n",
      "\t\tSEC\n",
      "\t\tAEC\n",
      "\t\tVSMC\n",
      "\t\tBlood\n",
      "\t\tHEV\n",
      "\tBone\n",
      "\t\tOsteoblast\n",
      "\t\tOsteocyte\n",
      "\t\tOsteoclast\n",
      "\tVimentin high\n",
      "\t\tVimentin high\n",
      "\tFibroblast\n",
      "\t\tSMA+_Fibroblast\n",
      "\t\tCD10_CAF\n",
      "\t\tFN_Cdh11_mCAF\n",
      "\t\tFibroblast\n",
      "\t\tvCAF\n",
      "\t\tCXCL13_CAF\n",
      "\t\tCD73_CAF\n",
      "\t\tCCL21_CAF\n",
      "\t\tIDO_CAF\n",
      "\t\tCD34_CAF\n",
      "\t\tCA9_CD10_CAF\n",
      "\tStroma\n",
      "\t\tStroma\n",
      "\tMyofibroblasts\n",
      "\t\tMyofibroblasts\n",
      "\tmuscle\n",
      "\t\tmuscle\n",
      "\tGlandular\n",
      "\t\tGlandular\n",
      "undefined\n",
      "\tundefined\n",
      "\t\tundefined\n",
      "\tCD44+ Undetermined\n",
      "\t\tCD44+ Undetermined\n",
      "\tCD34+ CD61+\n",
      "\t\tCD34+ CD61+\n",
      "HSCs\n",
      "\tHSCs\n",
      "\t\tHSCs\n",
      "Seg Artifact\n",
      "\tSeg Artifact\n",
      "\t\tSeg Artifact\n",
      "Cancer\n",
      "\tCancer\n",
      "\t\tCancer\n",
      "\thypoxic Cancer\n",
      "\t\thypoxic Cancer\n",
      "Epithelial\n",
      "\tEpithelial\n",
      "\t\tEpithelial\n",
      "unedfined\n",
      "\tunedfined\n",
      "\t\tunedfined\n",
      "Artifact\n",
      "\tArtifact\n",
      "\t\tArtifact\n",
      "Progenitor\n",
      "\tMyeloid_progenitor\n",
      "\t\tEarly Myeloid Progenitor\n",
      "\t\tIntermediate Myeloid\n",
      "\t\tGMP/Myeloblast\n",
      "\t\tGMP\n",
      "\tErythroid_mk_progenitor\n",
      "\t\tErythroid\n",
      "\t\tErythroblast\n",
      "\t\tMEP/Early Erythroblast\n",
      "\tSPINK2+ HSPC\n",
      "\t\tSPINK2+ HSPC\n",
      "\tHSPC\n",
      "\t\tHSPC\n",
      "\tMesenchymal_stem\n",
      "\t\tAdipo-MSC\n",
      "\t\tTHY1+ MSC\n",
      "\tHSC\n",
      "\t\tHSC\n",
      "\tLymphoid_progenitor\n",
      "\t\tCLP\n",
      "Endosteal\n",
      "\tEndosteal\n",
      "\t\tEndosteal\n",
      "Autofluorescent\n",
      "\tAutofluorescent\n",
      "\t\tAutofluorescent\n",
      "Megakaryocytes\n",
      "\tGATA1neg_Mks\n",
      "\t\tGATA1neg_Mks\n",
      "\tGATA1pos_Mks\n",
      "\t\tGATA1pos_Mks\n",
      "Neuronal\n",
      "\tSchwann Cells\n",
      "\t\tSchwann Cells\n",
      "hypoxia\n",
      "\thypoxia\n",
      "\t\thypoxia\n",
      "HLADR\n",
      "\tHLADR\n",
      "\t\tHLADR\n",
      "Trophoblast\n",
      "\tTrophoblast\n",
      "\t\tEVT1a\n",
      "\t\tEVT1b\n",
      "\t\tEVT2\n",
      "\t\tEVT1c\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# Group cell types by their level_1 and level_2 phenotypes\n",
    "\n",
    "grouped_hierarchy = defaultdict(lambda: defaultdict(list))\n",
    "\n",
    "for cell_type, levels in hierarchy_mappings.items():\n",
    "    lvl1 = levels['level_1_cell_type']\n",
    "    lvl2 = levels['level_2_cell_type']\n",
    "    grouped_hierarchy[lvl1][lvl2].append(cell_type)\n",
    "\n",
    "# Print the grouped hierarchy in a readable format\n",
    "for lvl1, lvl2_dict in grouped_hierarchy.items():\n",
    "    print(lvl1)\n",
    "    for lvl2, cell_types in lvl2_dict.items():\n",
    "        print(f\"\\t{lvl2}\")\n",
    "        for ct in cell_types:\n",
    "            print(f\"\\t\\t{ct}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
