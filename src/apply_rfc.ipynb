{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from random_forrest_classifier import MultiClassRandomForestClassifier\n",
    "import pandas as pd\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/Maps_data/cHL_2_MIBI/quantification/processed/kfolds/fold_1_test.csv')\n",
    "df2 = pd.read_csv('/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/Maps_data/cHL_2_MIBI/quantification/processed/kfolds/fold_1_train.csv')\n",
    "df = pd.concat([df1, df2])\n",
    "y = df['encoded_phenotype']\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y), y=y)\n",
    "class_weight_dict = {cls: weight for cls, weight in zip(np.unique(y), class_weights)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiClassRandomForestClassifier class initialized successfully with the following parameters:\n",
      "  n_estimators: 100\n",
      "  criterion: log_loss\n",
      "  max_depth: None\n",
      "  min_samples_split: 2\n",
      "  min_samples_leaf: 1\n",
      "  min_weight_fraction_leaf: 0.0\n",
      "  max_features: sqrt\n",
      "  max_leaf_nodes: None\n",
      "  min_impurity_decrease: 0.0\n",
      "  bootstrap: True\n",
      "  oob_score: False\n",
      "  n_jobs: 2\n",
      "  random_state: 42\n",
      "  verbose: 0\n",
      "  warm_start: False\n",
      "  class_weight: {np.int64(0): np.float64(0.7974118280906792), np.int64(1): np.float64(0.3509036693901371), np.int64(2): np.float64(0.4814761523447275), np.int64(3): np.float64(1.4665205792682927), np.int64(4): np.float64(0.970578591606134), np.int64(5): np.float64(3.312231020829747), np.int64(6): np.float64(3.9194846200855573), np.int64(7): np.float64(0.8109563348225576), np.int64(8): np.float64(3.9387410440122825), np.int64(9): np.float64(1.1430374858908097), np.int64(10): np.float64(1.2210147226805432), np.int64(11): np.float64(2.7092016333427202)}\n",
      "  ccp_alpha: 0.0\n",
      "  max_samples: None\n"
     ]
    }
   ],
   "source": [
    "cHL2 = MultiClassRandomForestClassifier(class_weight=class_weight_dict, random_state=rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data in fold_1_train.csv and fold_1_test.csv is clean.\n",
      "Data in fold_2_train.csv and fold_2_test.csv is clean.\n",
      "Data in fold_3_train.csv and fold_3_test.csv is clean.\n",
      "Data in fold_4_train.csv and fold_4_test.csv is clean.\n",
      "Data in fold_5_train.csv and fold_5_test.csv is clean.\n",
      "Training fold 1...\n",
      "Fold 1 results:\n",
      "Precision: 0.8620704082765352\n",
      "Recall: 0.8622937329464248\n",
      "Accuracy: 0.8622937329464248\n",
      "F1 Score: 0.8605050893760405\n",
      "Weighted F1 Score: 0.8616825472669862\n",
      "==================================================\n",
      "Training fold 2...\n",
      "Fold 2 results:\n",
      "Precision: 0.8616653533600763\n",
      "Recall: 0.8617523496037074\n",
      "Accuracy: 0.8617523496037074\n",
      "F1 Score: 0.8591010325209961\n",
      "Weighted F1 Score: 0.8610959116086403\n",
      "==================================================\n",
      "Training fold 3...\n",
      "Fold 3 results:\n",
      "Precision: 0.8612926854000997\n",
      "Recall: 0.8611026895924466\n",
      "Accuracy: 0.8611026895924466\n",
      "F1 Score: 0.8578876590479925\n",
      "Weighted F1 Score: 0.8604648933750816\n",
      "==================================================\n",
      "Training fold 4...\n",
      "Fold 4 results:\n",
      "Precision: 0.8610136155238242\n",
      "Recall: 0.8609294469227771\n",
      "Accuracy: 0.8609294469227771\n",
      "F1 Score: 0.8566831199494652\n",
      "Weighted F1 Score: 0.8603511245298752\n",
      "==================================================\n",
      "Training fold 5...\n",
      "Fold 5 results:\n",
      "Precision: 0.8580248705648347\n",
      "Recall: 0.8578729670615242\n",
      "Accuracy: 0.8578729670615242\n",
      "F1 Score: 0.853876643265342\n",
      "Weighted F1 Score: 0.8571511358874604\n",
      "==================================================\n",
      "Average Accuracy across all folds: 0.860790237225376\n",
      "Average F1 Score across all folds: 0.8576107088319673\n",
      "Average Weighted F1 Score across all folds: 0.8601491225336086\n",
      "Average Precision across all folds: 0.8608133866250739\n",
      "Average Recall across all folds: 0.860790237225376\n"
     ]
    }
   ],
   "source": [
    "cHL2.train_and_evaluate_manual(path='/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/Maps_data/cHL_2_MIBI/quantification/processed/kfolds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The path /Volumes/Lukas_SSD/phenotyping_benchmark/datasets/Maps_data/cHL_2_MIBI/results_rfc exists. Saving results in the specified directory.\n",
      "Saving average results...\n",
      "Saving confusion matrices...\n",
      "Saving classification reports...\n",
      "Saving model...\n",
      "Results and model saved successfully in /Volumes/Lukas_SSD/phenotyping_benchmark/datasets/Maps_data/cHL_2_MIBI/results_rfc.\n"
     ]
    }
   ],
   "source": [
    "cHL2.save_results(save_path='/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/Maps_data/cHL_2_MIBI/results_rfc', label_path='/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/Maps_data/cHL_2_MIBI/quantification/processed/labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/Maps_data/cHL_1_MIBI/quantification/processed/kfolds/fold_1_test.csv')\n",
    "df2 = pd.read_csv('/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/Maps_data/cHL_1_MIBI/quantification/processed/kfolds/fold_1_train.csv')\n",
    "df = pd.concat([df1, df2])\n",
    "y = df['encoded_phenotype']\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y), y=y)\n",
    "class_weight_dict = {cls: weight for cls, weight in zip(np.unique(y), class_weights)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiClassRandomForestClassifier class initialized successfully with the following parameters:\n",
      "  n_estimators: 100\n",
      "  criterion: log_loss\n",
      "  max_depth: None\n",
      "  min_samples_split: 2\n",
      "  min_samples_leaf: 1\n",
      "  min_weight_fraction_leaf: 0.0\n",
      "  max_features: sqrt\n",
      "  max_leaf_nodes: None\n",
      "  min_impurity_decrease: 0.0\n",
      "  bootstrap: True\n",
      "  oob_score: False\n",
      "  n_jobs: -1\n",
      "  random_state: 42\n",
      "  verbose: 0\n",
      "  warm_start: False\n",
      "  class_weight: {np.int64(0): np.float64(0.5850782111708621), np.int64(1): np.float64(0.260863662835747), np.int64(2): np.float64(0.46950427792601424), np.int64(3): np.float64(1.6965395673951253), np.int64(4): np.float64(12.175909992416729), np.int64(5): np.float64(1.0538448528084599), np.int64(6): np.float64(4.91653809916382), np.int64(7): np.float64(8.889857217389453), np.int64(8): np.float64(0.534171768935977), np.int64(9): np.float64(4.060294603952692), np.int64(10): np.float64(6.450795796955884), np.int64(11): np.float64(0.9075879948692306), np.int64(12): np.float64(1.8854164314393205), np.int64(13): np.float64(2.059416307573153)}\n",
      "  ccp_alpha: 0.0\n",
      "  max_samples: None\n"
     ]
    }
   ],
   "source": [
    "cHL1 = MultiClassRandomForestClassifier(class_weight=class_weight_dict, n_jobs=-1, random_state=rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data in fold_1_train.csv and fold_1_test.csv is clean.\n",
      "Data in fold_2_train.csv and fold_2_test.csv is clean.\n",
      "Data in fold_3_train.csv and fold_3_test.csv is clean.\n",
      "Data in fold_4_train.csv and fold_4_test.csv is clean.\n",
      "Data in fold_5_train.csv and fold_5_test.csv is clean.\n",
      "Training fold 1...\n",
      "Fold 1 results:\n",
      "Precision: 0.9036607787176242\n",
      "Recall: 0.9028897718664195\n",
      "Accuracy: 0.9028897718664195\n",
      "F1 Score: 0.8964280386363841\n",
      "Weighted F1 Score: 0.9025172587774916\n",
      "==================================================\n",
      "Training fold 2...\n",
      "Fold 2 results:\n",
      "Precision: 0.9029062562909558\n",
      "Recall: 0.9020843127097862\n",
      "Accuracy: 0.9020843127097862\n",
      "F1 Score: 0.8950544356514911\n",
      "Weighted F1 Score: 0.9017348091507644\n",
      "==================================================\n",
      "Training fold 3...\n",
      "Fold 3 results:\n",
      "Precision: 0.9032220266314073\n",
      "Recall: 0.9024196711690536\n",
      "Accuracy: 0.9024196711690536\n",
      "F1 Score: 0.8954132973136705\n",
      "Weighted F1 Score: 0.902068421154049\n",
      "==================================================\n",
      "Training fold 4...\n",
      "Fold 4 results:\n",
      "Precision: 0.9028573051503895\n",
      "Recall: 0.902066053837171\n",
      "Accuracy: 0.902066053837171\n",
      "F1 Score: 0.89560686223868\n",
      "Weighted F1 Score: 0.9017111619077649\n",
      "==================================================\n",
      "Training fold 5...\n",
      "Fold 5 results:\n",
      "Precision: 0.9033998470447965\n",
      "Recall: 0.9026259843698535\n",
      "Accuracy: 0.9026259843698535\n",
      "F1 Score: 0.8947800691718425\n",
      "Weighted F1 Score: 0.9022556242111694\n",
      "==================================================\n",
      "Average Accuracy across all folds: 0.9024171587904568\n",
      "Average F1 Score across all folds: 0.8954565406024135\n",
      "Average Weighted F1 Score across all folds: 0.9020574550402477\n",
      "Average Precision across all folds: 0.9032092427670346\n",
      "Average Recall across all folds: 0.9024171587904568\n"
     ]
    }
   ],
   "source": [
    "cHL1.train_and_evaluate_manual(path='/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/Maps_data/cHL_1_MIBI/quantification/processed/kfolds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The path /Volumes/Lukas_SSD/phenotyping_benchmark/datasets/Maps_data/cHL_1_MIBI/results_rfc exists. Saving results in the specified directory.\n",
      "Saving average results...\n",
      "Saving confusion matrices...\n",
      "Saving classification reports...\n",
      "Saving model...\n",
      "Results and model saved successfully in /Volumes/Lukas_SSD/phenotyping_benchmark/datasets/Maps_data/cHL_1_MIBI/results_rfc.\n"
     ]
    }
   ],
   "source": [
    "cHL1.save_results(save_path='/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/Maps_data/cHL_1_MIBI/results_rfc', label_path='/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/Maps_data/cHL_1_MIBI/quantification/processed/labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/Maps_data/cHL_CODEX/quantification/processed/kfolds/fold_1_test.csv')\n",
    "df2 = pd.read_csv('/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/Maps_data/cHL_CODEX/quantification/processed/kfolds/fold_1_train.csv')\n",
    "df = pd.concat([df1, df2])\n",
    "y = df['encoded_phenotype']\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y), y=y)\n",
    "class_weight_dict = {cls: weight for cls, weight in zip(np.unique(y), class_weights)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiClassRandomForestClassifier class initialized successfully with the following parameters:\n",
      "  n_estimators: 100\n",
      "  criterion: log_loss\n",
      "  max_depth: None\n",
      "  min_samples_split: 2\n",
      "  min_samples_leaf: 1\n",
      "  min_weight_fraction_leaf: 0.0\n",
      "  max_features: sqrt\n",
      "  max_leaf_nodes: None\n",
      "  min_impurity_decrease: 0.0\n",
      "  bootstrap: True\n",
      "  oob_score: False\n",
      "  n_jobs: -1\n",
      "  random_state: 42\n",
      "  verbose: 0\n",
      "  warm_start: False\n",
      "  class_weight: {np.int64(0): np.float64(0.5220243197303619), np.int64(1): np.float64(0.2255791324000251), np.int64(2): np.float64(0.4920103516266842), np.int64(3): np.float64(22.017463235294116), np.int64(4): np.float64(0.8773172026930519), np.int64(5): np.float64(0.9712470858532959), np.int64(6): np.float64(3.75597773538558), np.int64(7): np.float64(2.2438179093293367), np.int64(8): np.float64(2.726444979797788), np.int64(9): np.float64(1.1604043209378179), np.int64(10): np.float64(2.543533658950945), np.int64(11): np.float64(1.2230154610665327), np.int64(12): np.float64(1.152024237955163), np.int64(13): np.float64(2.4563352360118946), np.int64(14): np.float64(1.6551890920816252), np.int64(15): np.float64(2.522286957742524), np.int64(16): np.float64(1.023572140720695)}\n",
      "  ccp_alpha: 0.0\n",
      "  max_samples: None\n"
     ]
    }
   ],
   "source": [
    "cHL_CODEX = MultiClassRandomForestClassifier(class_weight=class_weight_dict, n_jobs=-1, random_state=rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data in fold_1_train.csv and fold_1_test.csv is clean.\n",
      "Data in fold_2_train.csv and fold_2_test.csv is clean.\n",
      "Data in fold_3_train.csv and fold_3_test.csv is clean.\n",
      "Data in fold_4_train.csv and fold_4_test.csv is clean.\n",
      "Data in fold_5_train.csv and fold_5_test.csv is clean.\n",
      "Training fold 1...\n",
      "Fold 1 results:\n",
      "Precision: 0.8463791923590518\n",
      "Recall: 0.8457872399638211\n",
      "Accuracy: 0.8457872399638211\n",
      "F1 Score: 0.8296163988567532\n",
      "Weighted F1 Score: 0.8438259633009321\n",
      "==================================================\n",
      "Training fold 2...\n",
      "Fold 2 results:\n",
      "Precision: 0.8462142519564259\n",
      "Recall: 0.8459611772072636\n",
      "Accuracy: 0.8459611772072636\n",
      "F1 Score: 0.8278851551872405\n",
      "Weighted F1 Score: 0.8442993943852981\n",
      "==================================================\n",
      "Training fold 3...\n",
      "Fold 3 results:\n",
      "Precision: 0.8471165430239502\n",
      "Recall: 0.8463438391428373\n",
      "Accuracy: 0.8463438391428373\n",
      "F1 Score: 0.8293152613991862\n",
      "Weighted F1 Score: 0.8445234106424091\n",
      "==================================================\n",
      "Training fold 4...\n",
      "Fold 4 results:\n",
      "Precision: 0.8457711714098585\n",
      "Recall: 0.8452654282334934\n",
      "Accuracy: 0.8452654282334934\n",
      "F1 Score: 0.8274292997932324\n",
      "Weighted F1 Score: 0.8434281651503955\n",
      "==================================================\n",
      "Training fold 5...\n",
      "Fold 5 results:\n",
      "Precision: 0.8453615387067266\n",
      "Recall: 0.8450219160926737\n",
      "Accuracy: 0.8450219160926737\n",
      "F1 Score: 0.8265829469180268\n",
      "Weighted F1 Score: 0.8432982662243546\n",
      "==================================================\n",
      "Average Accuracy across all folds: 0.8456759201280178\n",
      "Average F1 Score across all folds: 0.8281658124308878\n",
      "Average Weighted F1 Score across all folds: 0.8438750399406778\n",
      "Average Precision across all folds: 0.8461685394912026\n",
      "Average Recall across all folds: 0.8456759201280178\n"
     ]
    }
   ],
   "source": [
    "cHL_CODEX.train_and_evaluate_manual(path='/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/Maps_data/cHL_CODEX/quantification/processed/kfolds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The path /Volumes/Lukas_SSD/phenotyping_benchmark/datasets/Maps_data/cHL_CODEX/results_rfc exists. Saving results in the specified directory.\n",
      "Saving average results...\n",
      "Saving confusion matrices...\n",
      "Saving classification reports...\n",
      "Saving model...\n",
      "Results and model saved successfully in /Volumes/Lukas_SSD/phenotyping_benchmark/datasets/Maps_data/cHL_CODEX/results_rfc.\n"
     ]
    }
   ],
   "source": [
    "cHL_CODEX.save_results(save_path='/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/Maps_data/cHL_CODEX/results_rfc', label_path='/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/Maps_data/cHL_CODEX/quantification/processed/labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/MRL_CODEX/quantification/processed/kfolds/fold_1_test.csv')\n",
    "df2 = pd.read_csv('/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/MRL_CODEX/quantification/processed/kfolds/fold_1_train.csv')\n",
    "df = pd.concat([df1, df2])\n",
    "y = df['encoded_phenotype']\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y), y=y)\n",
    "class_weight_dict = {cls: weight for cls, weight in zip(np.unique(y), class_weights)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiClassRandomForestClassifier class initialized successfully with the following parameters:\n",
      "  n_estimators: 100\n",
      "  criterion: log_loss\n",
      "  max_depth: None\n",
      "  min_samples_split: 2\n",
      "  min_samples_leaf: 1\n",
      "  min_weight_fraction_leaf: 0.0\n",
      "  max_features: sqrt\n",
      "  max_leaf_nodes: None\n",
      "  min_impurity_decrease: 0.0\n",
      "  bootstrap: True\n",
      "  oob_score: False\n",
      "  n_jobs: -1\n",
      "  random_state: 42\n",
      "  verbose: 0\n",
      "  warm_start: False\n",
      "  class_weight: {np.int64(0): np.float64(0.13670032930191123), np.int64(1): np.float64(0.6390711238791678), np.int64(2): np.float64(3.287510076130766), np.int64(3): np.float64(0.9440744970344193), np.int64(4): np.float64(4.539108874159082), np.int64(5): np.float64(4.185487365444262), np.int64(6): np.float64(54.507053757053754), np.int64(7): np.float64(25.553501810080757), np.int64(8): np.float64(11.123416570701254), np.int64(9): np.float64(20.874118516833484), np.int64(10): np.float64(0.20272872883930299), np.int64(11): np.float64(1.8472410947046332), np.int64(12): np.float64(19.847004433870445), np.int64(13): np.float64(2.8463676970082354), np.int64(14): np.float64(13.22799841430013), np.int64(15): np.float64(0.41055908888555814), np.int64(16): np.float64(1.2165511046885462), np.int64(17): np.float64(0.7965090793882263), np.int64(18): np.float64(6.1893042627816), np.int64(19): np.float64(4.95144341022528), np.int64(20): np.float64(26.973140799529688), np.int64(21): np.float64(0.9846356276389701), np.int64(22): np.float64(0.2653632880277617), np.int64(23): np.float64(1.2836806138436574), np.int64(24): np.float64(5.192690207396089), np.int64(25): np.float64(15.870395191975096), np.int64(26): np.float64(4.057241234469647), np.int64(27): np.float64(5.821024168992642)}\n",
      "  ccp_alpha: 0.0\n",
      "  max_samples: None\n"
     ]
    }
   ],
   "source": [
    "MRL_CODEX = MultiClassRandomForestClassifier(class_weight=class_weight_dict, n_jobs=-1, random_state=rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data in fold_1_train.csv and fold_1_test.csv is clean.\n",
      "Data in fold_2_train.csv and fold_2_test.csv is clean.\n",
      "Data in fold_3_train.csv and fold_3_test.csv is clean.\n",
      "Data in fold_4_train.csv and fold_4_test.csv is clean.\n",
      "Data in fold_5_train.csv and fold_5_test.csv is clean.\n",
      "Training fold 1...\n",
      "Fold 1 results:\n",
      "Precision: 0.8287340701127084\n",
      "Recall: 0.8325239577444643\n",
      "Accuracy: 0.8325239577444643\n",
      "F1 Score: 0.7021906102235145\n",
      "Weighted F1 Score: 0.8269107932035253\n",
      "==================================================\n",
      "Training fold 2...\n",
      "Fold 2 results:\n",
      "Precision: 0.8265115655034087\n",
      "Recall: 0.8305203650728784\n",
      "Accuracy: 0.8305203650728784\n",
      "F1 Score: 0.7030406074024006\n",
      "Weighted F1 Score: 0.825051932268548\n",
      "==================================================\n",
      "Training fold 3...\n",
      "Fold 3 results:\n",
      "Precision: 0.8266587673828013\n",
      "Recall: 0.8304863097670617\n",
      "Accuracy: 0.8304863097670617\n",
      "F1 Score: 0.6987757443115815\n",
      "Weighted F1 Score: 0.8249123829017946\n",
      "==================================================\n",
      "Training fold 4...\n",
      "Fold 4 results:\n",
      "Precision: 0.826536640540335\n",
      "Recall: 0.8303773327884484\n",
      "Accuracy: 0.8303773327884484\n",
      "F1 Score: 0.7058760832310798\n",
      "Weighted F1 Score: 0.8248677510473672\n",
      "==================================================\n",
      "Training fold 5...\n",
      "Fold 5 results:\n",
      "Precision: 0.8280659662368133\n",
      "Recall: 0.8320324206511375\n",
      "Accuracy: 0.8320324206511375\n",
      "F1 Score: 0.7054500592600473\n",
      "Weighted F1 Score: 0.8266005372844042\n",
      "==================================================\n",
      "Average Accuracy across all folds: 0.8311880772047981\n",
      "Average F1 Score across all folds: 0.7030666208857248\n",
      "Average Weighted F1 Score across all folds: 0.8256686793411279\n",
      "Average Precision across all folds: 0.8273014019552132\n",
      "Average Recall across all folds: 0.8311880772047981\n"
     ]
    }
   ],
   "source": [
    "MRL_CODEX.train_and_evaluate_manual(path='/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/MRL_CODEX/quantification/processed/kfolds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The path /Volumes/Lukas_SSD/phenotyping_benchmark/datasets/MRL_CODEX/results_rfc exists. Saving results in the specified directory.\n",
      "Saving average results...\n",
      "Saving confusion matrices...\n",
      "Saving classification reports...\n",
      "Saving model...\n",
      "Results and model saved successfully in /Volumes/Lukas_SSD/phenotyping_benchmark/datasets/MRL_CODEX/results_rfc.\n"
     ]
    }
   ],
   "source": [
    "MRL_CODEX.save_results(save_path='/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/MRL_CODEX/results_rfc', label_path='/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/MRL_CODEX/quantification/processed/labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/TB_MIBI_atlas/quantification/processed/sarc/kfolds/fold_1_test.csv')\n",
    "df2 = pd.read_csv('/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/TB_MIBI_atlas/quantification/processed/sarc/kfolds/fold_1_train.csv')\n",
    "df = pd.concat([df1, df2])\n",
    "y = df['encoded_phenotype']\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y), y=y)\n",
    "class_weight_dict = {cls: weight for cls, weight in zip(np.unique(y), class_weights)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiClassRandomForestClassifier class initialized successfully with the following parameters:\n",
      "  n_estimators: 100\n",
      "  criterion: log_loss\n",
      "  max_depth: None\n",
      "  min_samples_split: 2\n",
      "  min_samples_leaf: 1\n",
      "  min_weight_fraction_leaf: 0.0\n",
      "  max_features: sqrt\n",
      "  max_leaf_nodes: None\n",
      "  min_impurity_decrease: 0.0\n",
      "  bootstrap: True\n",
      "  oob_score: False\n",
      "  n_jobs: -1\n",
      "  random_state: 42\n",
      "  verbose: 0\n",
      "  warm_start: False\n",
      "  class_weight: {np.int64(0): np.float64(0.43226548129981607), np.int64(1): np.float64(0.49053748477996173), np.int64(2): np.float64(0.6179009640666082), np.int64(3): np.float64(0.5171648633779571), np.int64(4): np.float64(1.8977792732166892), np.int64(5): np.float64(0.9638072453861928), np.int64(6): np.float64(2.2153181461115476), np.int64(7): np.float64(5.497270955165692), np.int64(8): np.float64(0.28520428802589), np.int64(9): np.float64(1.3519175455417065), np.int64(10): np.float64(0.5005502307419241), np.int64(11): np.float64(6.512933025404157), np.int64(12): np.float64(1.2760633484162895), np.int64(13): np.float64(3.234059633027523), np.int64(14): np.float64(1.1721113881961762), np.int64(15): np.float64(47.79830508474576), np.int64(16): np.float64(82.94411764705882), np.int64(17): np.float64(0.9472959355055425), np.int64(18): np.float64(11.190873015873017), np.int64(19): np.float64(2.6529633113828788)}\n",
      "  ccp_alpha: 0.0\n",
      "  max_samples: None\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "NaN values found in the fold data. Please handle missing values before training.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m sarc \u001b[38;5;241m=\u001b[39m MultiClassRandomForestClassifier(class_weight\u001b[38;5;241m=\u001b[39mclass_weight_dict, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, random_state\u001b[38;5;241m=\u001b[39mrs)\n\u001b[0;32m----> 2\u001b[0m \u001b[43msarc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_and_evaluate_manual\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/TB_MIBI_atlas/quantification/processed/sarc/kfolds\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m sarc\u001b[38;5;241m.\u001b[39msave_results(save_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/TB_MIBI_atlas/quantification/processed/sarc/results_rfc\u001b[39m\u001b[38;5;124m'\u001b[39m, label_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/TB_MIBI_atlas/quantification/processed/sarc/labels.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/PhD_Schapiro/Projects/phenotype_benchmark/github/pheno_benchmark_small/src/random_forrest_classifier.py:180\u001b[0m, in \u001b[0;36mMultiClassRandomForestClassifier.train_and_evaluate_manual\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m    178\u001b[0m test_data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(path, test_file))\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m train_data\u001b[38;5;241m.\u001b[39misnull()\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39many() \u001b[38;5;129;01mor\u001b[39;00m test_data\u001b[38;5;241m.\u001b[39misnull()\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m--> 180\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNaN values found in the fold data. Please handle missing values before training.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is clean.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: NaN values found in the fold data. Please handle missing values before training."
     ]
    }
   ],
   "source": [
    "sarc = MultiClassRandomForestClassifier(class_weight=class_weight_dict, n_jobs=-1, random_state=rs)\n",
    "sarc.train_and_evaluate_manual(path='/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/TB_MIBI_atlas/quantification/processed/sarc/kfolds')\n",
    "sarc.save_results(save_path='/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/TB_MIBI_atlas/quantification/processed/sarc/results_rfc', label_path='/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/TB_MIBI_atlas/quantification/processed/sarc/labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/TB_MIBI_atlas/quantification/processed/TB/kfolds/fold_1_test.csv')\n",
    "df2 = pd.read_csv('/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/TB_MIBI_atlas/quantification/processed/TB/kfolds/fold_1_train.csv')\n",
    "df = pd.concat([df1, df2])\n",
    "y = df['encoded_phenotype']\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y), y=y)\n",
    "class_weight_dict = {cls: weight for cls, weight in zip(np.unique(y), class_weights)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiClassRandomForestClassifier class initialized successfully with the following parameters:\n",
      "  n_estimators: 100\n",
      "  criterion: log_loss\n",
      "  max_depth: None\n",
      "  min_samples_split: 2\n",
      "  min_samples_leaf: 1\n",
      "  min_weight_fraction_leaf: 0.0\n",
      "  max_features: sqrt\n",
      "  max_leaf_nodes: None\n",
      "  min_impurity_decrease: 0.0\n",
      "  bootstrap: True\n",
      "  oob_score: False\n",
      "  n_jobs: -1\n",
      "  random_state: 42\n",
      "  verbose: 0\n",
      "  warm_start: False\n",
      "  class_weight: {np.int64(0): np.float64(0.6754814305364512), np.int64(1): np.float64(0.5556404163837972), np.int64(2): np.float64(0.8466810344827587), np.int64(3): np.float64(0.5666685898915301), np.int64(4): np.float64(1.6579169480081026), np.int64(5): np.float64(0.8437714776632302), np.int64(6): np.float64(3.3497612551159617), np.int64(7): np.float64(0.3780408006158584), np.int64(8): np.float64(2.1148794142980187), np.int64(9): np.float64(0.5252139037433156), np.int64(10): np.float64(6.107898009950249), np.int64(11): np.float64(1.4563315539739028), np.int64(12): np.float64(2.822270114942529), np.int64(13): np.float64(1.0395321761219305), np.int64(14): np.float64(10.912777777777778), np.int64(15): np.float64(2.4578328328328327)}\n",
      "  ccp_alpha: 0.0\n",
      "  max_samples: None\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "NaN values found in the fold data. Please handle missing values before training.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m tb \u001b[38;5;241m=\u001b[39m MultiClassRandomForestClassifier(class_weight\u001b[38;5;241m=\u001b[39mclass_weight_dict, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, random_state\u001b[38;5;241m=\u001b[39mrs)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_and_evaluate_manual\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/TB_MIBI_atlas/quantification/processed/TB/kfolds\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m tb\u001b[38;5;241m.\u001b[39msave_results(save_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/TB_MIBI_atlas/quantification/processed/TB/results_rfc\u001b[39m\u001b[38;5;124m'\u001b[39m, label_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/TB_MIBI_atlas/quantification/processed/TB/labels.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/PhD_Schapiro/Projects/phenotype_benchmark/github/pheno_benchmark_small/src/random_forrest_classifier.py:180\u001b[0m, in \u001b[0;36mMultiClassRandomForestClassifier.train_and_evaluate_manual\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m    178\u001b[0m test_data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(path, test_file))\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m train_data\u001b[38;5;241m.\u001b[39misnull()\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39many() \u001b[38;5;129;01mor\u001b[39;00m test_data\u001b[38;5;241m.\u001b[39misnull()\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m--> 180\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNaN values found in the fold data. Please handle missing values before training.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is clean.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: NaN values found in the fold data. Please handle missing values before training."
     ]
    }
   ],
   "source": [
    "tb = MultiClassRandomForestClassifier(class_weight=class_weight_dict, n_jobs=-1, random_state=rs)\n",
    "tb.train_and_evaluate_manual(path='/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/TB_MIBI_atlas/quantification/processed/TB/kfolds')\n",
    "tb.save_results(save_path='/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/TB_MIBI_atlas/quantification/processed/TB/results_rfc', label_path='/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/TB_MIBI_atlas/quantification/processed/TB/labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/tonsil_CODEX/quantification/processed/kfolds/fold_1_test.csv')\n",
    "df2 = pd.read_csv('/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/tonsil_CODEX/quantification/processed/kfolds/fold_1_train.csv')\n",
    "df = pd.concat([df1, df2])\n",
    "y = df['encoded_phenotype']\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y), y=y)\n",
    "class_weight_dict = {cls: weight for cls, weight in zip(np.unique(y), class_weights)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiClassRandomForestClassifier class initialized successfully with the following parameters:\n",
      "  n_estimators: 100\n",
      "  criterion: log_loss\n",
      "  max_depth: None\n",
      "  min_samples_split: 2\n",
      "  min_samples_leaf: 1\n",
      "  min_weight_fraction_leaf: 0.0\n",
      "  max_features: sqrt\n",
      "  max_leaf_nodes: None\n",
      "  min_impurity_decrease: 0.0\n",
      "  bootstrap: True\n",
      "  oob_score: False\n",
      "  n_jobs: -1\n",
      "  random_state: 42\n",
      "  verbose: 0\n",
      "  warm_start: False\n",
      "  class_weight: {np.int64(0): np.float64(0.1744224680097024), np.int64(1): np.float64(25.55066489361702), np.int64(2): np.float64(0.25955459614844273), np.int64(3): np.float64(1.1169949307041205), np.int64(4): np.float64(36.0625), np.int64(5): np.float64(10.066062447611065), np.int64(6): np.float64(3.041745820668693), np.int64(7): np.float64(1.225764264570787), np.int64(8): np.float64(36.39034090909091), np.int64(9): np.float64(8.46286997885835), np.int64(10): np.float64(0.2757160486740902), np.int64(11): np.float64(71.90905688622755), np.int64(12): np.float64(142.96205357142858), np.int64(13): np.float64(49.829097510373444), np.int64(14): np.float64(86.3943345323741), np.int64(15): np.float64(2.611746955197912)}\n",
      "  ccp_alpha: 0.0\n",
      "  max_samples: None\n",
      "Data in fold_1_train.csv and fold_1_test.csv is clean.\n",
      "Data in fold_2_train.csv and fold_2_test.csv is clean.\n",
      "Data in fold_3_train.csv and fold_3_test.csv is clean.\n",
      "Data in fold_4_train.csv and fold_4_test.csv is clean.\n",
      "Data in fold_5_train.csv and fold_5_test.csv is clean.\n",
      "Training fold 1...\n",
      "Fold 1 results:\n",
      "Precision: 0.862562745535245\n",
      "Recall: 0.8620052564469541\n",
      "Accuracy: 0.8620052564469541\n",
      "F1 Score: 0.6886300637593865\n",
      "Weighted F1 Score: 0.8591963975443191\n",
      "==================================================\n",
      "Training fold 2...\n",
      "Fold 2 results:\n",
      "Precision: 0.8626224575467685\n",
      "Recall: 0.8618195066097637\n",
      "Accuracy: 0.8618195066097637\n",
      "F1 Score: 0.6931823388421733\n",
      "Weighted F1 Score: 0.8591922950725615\n",
      "==================================================\n",
      "Training fold 3...\n",
      "Fold 3 results:\n",
      "Precision: 0.8630238437827936\n",
      "Recall: 0.8623399604455085\n",
      "Accuracy: 0.8623399604455085\n",
      "F1 Score: 0.7020733868669244\n",
      "Weighted F1 Score: 0.8596916961730098\n",
      "==================================================\n",
      "Training fold 4...\n",
      "Fold 4 results:\n",
      "Precision: 0.860624258800535\n",
      "Recall: 0.860102008951806\n",
      "Accuracy: 0.860102008951806\n",
      "F1 Score: 0.698523268047099\n",
      "Weighted F1 Score: 0.857510293168956\n",
      "==================================================\n",
      "Training fold 5...\n",
      "Fold 5 results:\n",
      "Precision: 0.8607751423848689\n",
      "Recall: 0.8603362131778911\n",
      "Accuracy: 0.8603362131778911\n",
      "F1 Score: 0.6544107364027903\n",
      "Weighted F1 Score: 0.8570999025799453\n",
      "==================================================\n",
      "Average Accuracy across all folds: 0.8613205891263845\n",
      "Average F1 Score across all folds: 0.6873639587836746\n",
      "Average Weighted F1 Score across all folds: 0.8585381169077582\n",
      "Average Precision across all folds: 0.8619216896100422\n",
      "Average Recall across all folds: 0.8613205891263845\n",
      "The path /Volumes/Lukas_SSD/phenotyping_benchmark/datasets/tonsil_CODEX/results_rfc exists. Saving results in the specified directory.\n",
      "Saving average results...\n",
      "Saving confusion matrices...\n",
      "Saving classification reports...\n",
      "Saving model...\n",
      "Results and model saved successfully in /Volumes/Lukas_SSD/phenotyping_benchmark/datasets/tonsil_CODEX/results_rfc.\n"
     ]
    }
   ],
   "source": [
    "tonsil_CODEX = MultiClassRandomForestClassifier(class_weight=class_weight_dict, n_jobs=-1, random_state=rs)\n",
    "tonsil_CODEX.train_and_evaluate_manual(path='/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/tonsil_CODEX/quantification/processed/kfolds')\n",
    "tonsil_CODEX.save_results(save_path='/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/tonsil_CODEX/results_rfc', label_path='/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/tonsil_CODEX/quantification/processed/labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/tonsil_CODEX2/quantification/processed/kfolds/fold_1_test.csv')\n",
    "df2 = pd.read_csv('/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/tonsil_CODEX2/quantification/processed/kfolds/fold_1_train.csv')\n",
    "df = pd.concat([df1, df2])\n",
    "y = df['encoded_phenotype']\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y), y=y)\n",
    "class_weight_dict = {cls: weight for cls, weight in zip(np.unique(y), class_weights)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiClassRandomForestClassifier class initialized successfully with the following parameters:\n",
      "  n_estimators: 100\n",
      "  criterion: log_loss\n",
      "  max_depth: None\n",
      "  min_samples_split: 2\n",
      "  min_samples_leaf: 1\n",
      "  min_weight_fraction_leaf: 0.0\n",
      "  max_features: sqrt\n",
      "  max_leaf_nodes: None\n",
      "  min_impurity_decrease: 0.0\n",
      "  bootstrap: True\n",
      "  oob_score: False\n",
      "  n_jobs: -1\n",
      "  random_state: 42\n",
      "  verbose: 0\n",
      "  warm_start: False\n",
      "  class_weight: {np.int64(0): np.float64(3.057356853854752), np.int64(1): np.float64(0.5460073381942232), np.int64(2): np.float64(11.59560239435148), np.int64(3): np.float64(0.14131940144785493), np.int64(4): np.float64(12.828377188153693), np.int64(5): np.float64(0.33684614184898864), np.int64(6): np.float64(25.94005877245709), np.int64(7): np.float64(25.88646360970408), np.int64(8): np.float64(5.9020405372207465), np.int64(9): np.float64(0.4771153231948505), np.int64(10): np.float64(1.1906157893311684), np.int64(11): np.float64(2.031298376636961), np.int64(12): np.float64(3.3748278483762353), np.int64(13): np.float64(5.427746593688133), np.int64(14): np.float64(1.346099815968568), np.int64(15): np.float64(15.499853674758896), np.int64(16): np.float64(8.236473137129467), np.int64(17): np.float64(1.2207780302145317), np.int64(18): np.float64(1.8133512717720148), np.int64(19): np.float64(3.9037383975998674), np.int64(20): np.float64(1.582983223958825), np.int64(21): np.float64(10.950370039705847), np.int64(22): np.float64(0.9665983943139002), np.int64(23): np.float64(2.593558403401092), np.int64(24): np.float64(21.94229139596633), np.int64(25): np.float64(3.4769108886074025), np.int64(26): np.float64(18.883268104139827), np.int64(27): np.float64(0.12346424195866253), np.int64(28): np.float64(2.225869491089943), np.int64(29): np.float64(1.2085898765688206), np.int64(30): np.float64(62.54100692394397)}\n",
      "  ccp_alpha: 0.0\n",
      "  max_samples: None\n",
      "Data in fold_1_train.csv and fold_1_test.csv is clean.\n",
      "Data in fold_2_train.csv and fold_2_test.csv is clean.\n",
      "Data in fold_3_train.csv and fold_3_test.csv is clean.\n",
      "Data in fold_4_train.csv and fold_4_test.csv is clean.\n",
      "Data in fold_5_train.csv and fold_5_test.csv is clean.\n",
      "Training fold 1...\n",
      "Fold 1 results:\n",
      "Precision: 0.8072044308128293\n",
      "Recall: 0.8119747425876618\n",
      "Accuracy: 0.8119747425876618\n",
      "F1 Score: 0.6344739799217156\n",
      "Weighted F1 Score: 0.7986327737401413\n",
      "==================================================\n",
      "Training fold 2...\n",
      "Fold 2 results:\n",
      "Precision: 0.8068233860331928\n",
      "Recall: 0.8118567373482292\n",
      "Accuracy: 0.8118567373482292\n",
      "F1 Score: 0.6356108768419684\n",
      "Weighted F1 Score: 0.7983857931381662\n",
      "==================================================\n",
      "Training fold 3...\n",
      "Fold 3 results:\n",
      "Precision: 0.8074021111055417\n",
      "Recall: 0.8123394860549991\n",
      "Accuracy: 0.8123394860549991\n",
      "F1 Score: 0.6313956322091469\n",
      "Weighted F1 Score: 0.7989131659599273\n",
      "==================================================\n",
      "Training fold 4...\n",
      "Fold 4 results:\n",
      "Precision: 0.8077358446754029\n",
      "Recall: 0.8129934775145897\n",
      "Accuracy: 0.8129934775145897\n",
      "F1 Score: 0.6360658985560007\n",
      "Weighted F1 Score: 0.7998287421445736\n",
      "==================================================\n",
      "Training fold 5...\n",
      "Fold 5 results:\n",
      "Precision: 0.8078861043837384\n",
      "Recall: 0.812920528664607\n",
      "Accuracy: 0.812920528664607\n",
      "F1 Score: 0.6338764480338427\n",
      "Weighted F1 Score: 0.7995161176340851\n",
      "==================================================\n",
      "Average Accuracy across all folds: 0.8124169944340174\n",
      "Average F1 Score across all folds: 0.6342845671125349\n",
      "Average Weighted F1 Score across all folds: 0.7990553185233786\n",
      "Average Precision across all folds: 0.8074103754021411\n",
      "Average Recall across all folds: 0.8124169944340174\n",
      "The path /Volumes/Lukas_SSD/phenotyping_benchmark/datasets/tonsil_CODEX2/results_rfc exists. Saving results in the specified directory.\n",
      "Saving average results...\n",
      "Saving confusion matrices...\n",
      "Saving classification reports...\n",
      "Saving model...\n",
      "Results and model saved successfully in /Volumes/Lukas_SSD/phenotyping_benchmark/datasets/tonsil_CODEX2/results_rfc.\n"
     ]
    }
   ],
   "source": [
    "tonsil_CODEX2 = MultiClassRandomForestClassifier(class_weight=class_weight_dict, n_jobs=-1, random_state=rs)\n",
    "tonsil_CODEX2.train_and_evaluate_manual(path='/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/tonsil_CODEX2/quantification/processed/kfolds')\n",
    "tonsil_CODEX2.save_results(save_path='/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/tonsil_CODEX2/results_rfc', label_path='/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/tonsil_CODEX2/quantification/processed/labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "del cHL1, cHL2, cHL_CODEX, MRL_CODEX, sarc, tb, tonsil_CODEX"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cML_benchmark",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
