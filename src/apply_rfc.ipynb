{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from models_classes.gridsearch_multi import Tune_Eval\n",
    "import pandas as pd\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = 20240925\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 250],\n",
    "    'max_depth': [20, 25, 30, 40],\n",
    "    'min_samples_split' : [2, 3],\n",
    "    'min_samples_leaf' : [1, 2]\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/Maps_data/cHL_2_MIBI/quantification/processed/kfolds/fold_1_test.csv')\n",
    "df2 = pd.read_csv('/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/Maps_data/cHL_2_MIBI/quantification/processed/kfolds/fold_1_train.csv')\n",
    "df = pd.concat([df1, df2])\n",
    "y = df['encoded_phenotype']\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y), y=y)\n",
    "class_weight_dict = {cls: weight for cls, weight in zip(np.unique(y), class_weights)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GirdSearcher class initialized successfully with the following model parameters:\n",
      "Random State: 20240925\n",
      "Model: RandomForestClassifier(class_weight={np.int64(0): np.float64(0.7974301009434999),\n",
      "                                     np.int64(1): np.float64(0.3509042803061704),\n",
      "                                     np.int64(2): np.float64(0.4814830612902614),\n",
      "                                     np.int64(3): np.float64(1.4664674634794157),\n",
      "                                     np.int64(4): np.float64(0.9705837393713576),\n",
      "                                     np.int64(5): np.float64(3.3121739697443924),\n",
      "                                     np.int64(6): np.float64(3.9194058641975307),\n",
      "                                     np.int64(7): np.float64(0.8109503967303671),\n",
      "                                     np.int64(8): np.float64(3.938551601147554),\n",
      "                                     np.int64(9): np.float64(1.1430387722496005),\n",
      "                                     np.int64(10): np.float64(1.2210163217230354),\n",
      "                                     np.int64(11): np.float64(2.709093333333333)},\n",
      "                       criterion='log_loss', n_jobs=-1, random_state=20240925)\n"
     ]
    }
   ],
   "source": [
    "cHL2 = Tune_Eval(class_weight=class_weight_dict, random_state=rs, model='random_forest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taking data from fold_1_train.csv and fold_1_test.csv for fold 1. No NANs found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 1:  75%|███████▌  | 24/32 [02:58<01:01,  7.68s/it]/Users/lukashat/miniforge3/envs/cML_benchmark/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "Fold 1: 100%|██████████| 32/32 [07:13<00:00, 13.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outer Fold 1 completed\n",
      "Best parameters for Fold 1: {'n_estimators': 250, 'max_depth': 40, 'min_samples_split': 2, 'min_samples_leaf': 1}\n",
      "classification report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.92      0.92      4826\n",
      "           1       0.84      0.85      0.84     10966\n",
      "           2       0.85      0.86      0.85      7992\n",
      "           3       0.81      0.88      0.84      2624\n",
      "           4       0.81      0.76      0.78      3965\n",
      "           5       0.94      0.94      0.94      1162\n",
      "           6       0.87      0.60      0.71       982\n",
      "           7       0.88      0.87      0.87      4745\n",
      "           8       0.87      0.88      0.87       977\n",
      "           9       0.88      0.94      0.91      3367\n",
      "          10       0.87      0.87      0.87      3152\n",
      "          11       0.88      0.84      0.86      1420\n",
      "\n",
      "    accuracy                           0.86     46178\n",
      "   macro avg       0.87      0.85      0.86     46178\n",
      "weighted avg       0.86      0.86      0.86     46178\n",
      "\n",
      "Taking data from fold_2_train.csv and fold_2_test.csv for fold 2. No NANs found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 2:  25%|██▌       | 8/32 [00:12<00:00, 29.01it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcHL2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_tune_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/Maps_data/cHL_2_MIBI/quantification/processed/kfolds\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_processes\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/PhD_Schapiro/Projects/phenotype_benchmark/github/pheno_benchmark_small/src/models_classes/gridsearch_multi.py:128\u001b[0m, in \u001b[0;36mTune_Eval.train_tune_evaluate\u001b[0;34m(self, path, param_grid, dumb_nonnumericals, n_processes, drop_xy)\u001b[0m\n\u001b[1;32m    126\u001b[0m param_combinations \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(param_grid\u001b[38;5;241m.\u001b[39mkeys(), v)) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m itertools\u001b[38;5;241m.\u001b[39mproduct(\u001b[38;5;241m*\u001b[39mparam_grid\u001b[38;5;241m.\u001b[39mvalues())]\n\u001b[1;32m    127\u001b[0m args \u001b[38;5;241m=\u001b[39m [(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, X_train_scaled, y_train, X_val_scaled, y_val, param) \u001b[38;5;28;01mfor\u001b[39;00m param \u001b[38;5;129;01min\u001b[39;00m param_combinations]\n\u001b[0;32m--> 128\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_processes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mFold \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m accuracy, model, params \u001b[38;5;129;01min\u001b[39;00m results:\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m accuracy \u001b[38;5;241m>\u001b[39m best_score:\n",
      "File \u001b[0;32m~/miniforge3/envs/cML_benchmark/lib/python3.10/site-packages/joblib/parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[1;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/cML_benchmark/lib/python3.10/site-packages/joblib/parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/cML_benchmark/lib/python3.10/site-packages/joblib/parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[1;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cHL2.train_tune_evaluate(path='/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/Maps_data/cHL_2_MIBI/quantification/processed/kfolds', param_grid = param_grid, n_processes = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cHL2.save_results(save_path='/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/Maps_data/cHL_2_MIBI/results_rfc_25', label_path='/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/Maps_data/cHL_2_MIBI/quantification/processed/labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/Maps_data/cHL_1_MIBI/quantification/processed/kfolds/fold_1_test.csv')\n",
    "df2 = pd.read_csv('/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/Maps_data/cHL_1_MIBI/quantification/processed/kfolds/fold_1_train.csv')\n",
    "df = pd.concat([df1, df2])\n",
    "y = df['encoded_phenotype']\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y), y=y)\n",
    "class_weight_dict = {cls: weight for cls, weight in zip(np.unique(y), class_weights)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cHL1 = MultiClassRandomForestClassifier(class_weight=class_weight_dict, n_jobs=-1, random_state=rs, max_depth=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cHL1.train_and_evaluate_manual(path='/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/Maps_data/cHL_1_MIBI/quantification/processed/kfolds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cHL1.save_results(save_path='/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/Maps_data/cHL_1_MIBI/results_rfc_25', label_path='/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/Maps_data/cHL_1_MIBI/quantification/processed/labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/Maps_data/cHL_CODEX/quantification/processed/kfolds/fold_1_test.csv')\n",
    "df2 = pd.read_csv('/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/Maps_data/cHL_CODEX/quantification/processed/kfolds/fold_1_train.csv')\n",
    "df = pd.concat([df1, df2])\n",
    "y = df['encoded_phenotype']\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y), y=y)\n",
    "class_weight_dict = {cls: weight for cls, weight in zip(np.unique(y), class_weights)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cHL_CODEX = MultiClassRandomForestClassifier(class_weight=class_weight_dict, n_jobs=-1, random_state=rs, max_depth=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cHL_CODEX.train_and_evaluate_manual(path='/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/Maps_data/cHL_CODEX/quantification/processed/kfolds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cHL_CODEX.save_results(save_path='/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/Maps_data/cHL_CODEX/results_rfc_25', label_path='/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/Maps_data/cHL_CODEX/quantification/processed/labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/MRL_CODEX/quantification/processed/kfolds/fold_1_test.csv')\n",
    "df2 = pd.read_csv('/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/MRL_CODEX/quantification/processed/kfolds/fold_1_train.csv')\n",
    "df = pd.concat([df1, df2])\n",
    "y = df['encoded_phenotype']\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y), y=y)\n",
    "class_weight_dict = {cls: weight for cls, weight in zip(np.unique(y), class_weights)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MRL_CODEX = MultiClassRandomForestClassifier(class_weight=class_weight_dict, n_jobs=-1, random_state=rs, max_depth=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MRL_CODEX.train_and_evaluate_manual(path='/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/MRL_CODEX/quantification/processed/kfolds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MRL_CODEX.save_results(save_path='/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/MRL_CODEX/results_rfc_25', label_path='/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/MRL_CODEX/quantification/processed/labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/TB_MIBI_atlas/quantification/processed/sarc/kfolds/fold_1_test.csv')\n",
    "df2 = pd.read_csv('/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/TB_MIBI_atlas/quantification/processed/sarc/kfolds/fold_1_train.csv')\n",
    "df = pd.concat([df1, df2])\n",
    "y = df['encoded_phenotype']\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y), y=y)\n",
    "class_weight_dict = {cls: weight for cls, weight in zip(np.unique(y), class_weights)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sarc = MultiClassRandomForestClassifier(class_weight=class_weight_dict, n_jobs=-1, random_state=rs, max_depth=25)\n",
    "sarc.train_and_evaluate_manual(path='/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/TB_MIBI_atlas/quantification/processed/sarc/kfolds')\n",
    "sarc.save_results(save_path='/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/TB_MIBI_atlas/quantification/processed/sarc/results_rfc_25', label_path='/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/TB_MIBI_atlas/quantification/processed/sarc/labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/TB_MIBI_atlas/quantification/processed/TB/kfolds/fold_1_test.csv')\n",
    "df2 = pd.read_csv('/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/TB_MIBI_atlas/quantification/processed/TB/kfolds/fold_1_train.csv')\n",
    "df = pd.concat([df1, df2])\n",
    "y = df['encoded_phenotype']\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y), y=y)\n",
    "class_weight_dict = {cls: weight for cls, weight in zip(np.unique(y), class_weights)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb = MultiClassRandomForestClassifier(class_weight=class_weight_dict, n_jobs=-1, random_state=rs, max_depth=25)\n",
    "tb.train_and_evaluate_manual(path='/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/TB_MIBI_atlas/quantification/processed/TB/kfolds')\n",
    "tb.save_results(save_path='/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/TB_MIBI_atlas/quantification/processed/TB/results_rfc_25', label_path='/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/TB_MIBI_atlas/quantification/processed/TB/labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/tonsil_CODEX/quantification/processed/kfolds/fold_1_test.csv')\n",
    "df2 = pd.read_csv('/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/tonsil_CODEX/quantification/processed/kfolds/fold_1_train.csv')\n",
    "df = pd.concat([df1, df2])\n",
    "y = df['encoded_phenotype']\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y), y=y)\n",
    "class_weight_dict = {cls: weight for cls, weight in zip(np.unique(y), class_weights)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tonsil_CODEX = MultiClassRandomForestClassifier(class_weight=class_weight_dict, n_jobs=-1, random_state=rs, max_depth=25)\n",
    "tonsil_CODEX.train_and_evaluate_manual(path='/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/tonsil_CODEX/quantification/processed/kfolds')\n",
    "tonsil_CODEX.save_results(save_path='/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/tonsil_CODEX/results_rfc_25', label_path='/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/tonsil_CODEX/quantification/processed/labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/tonsil_CODEX2/quantification/processed/kfolds/fold_1_test.csv')\n",
    "df2 = pd.read_csv('/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/tonsil_CODEX2/quantification/processed/kfolds/fold_1_train.csv')\n",
    "df = pd.concat([df1, df2])\n",
    "y = df['encoded_phenotype']\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y), y=y)\n",
    "class_weight_dict = {cls: weight for cls, weight in zip(np.unique(y), class_weights)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tonsil_CODEX2 = MultiClassRandomForestClassifier(class_weight=class_weight_dict, n_jobs=-1, random_state=rs, max_depth=25)\n",
    "tonsil_CODEX2.train_and_evaluate_manual(path='/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/tonsil_CODEX2/quantification/processed/kfolds')\n",
    "tonsil_CODEX2.save_results(save_path='/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/tonsil_CODEX2/results_rfc_25', label_path='/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/tonsil_CODEX2/quantification/processed/labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "del cHL1, cHL2, cHL_CODEX, MRL_CODEX, sarc, tb, tonsil_CODEX, tonsil_CODEX2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/lymphoma_CODEX/quantification/processed/kfolds/fold_1_test.csv')\n",
    "df2 = pd.read_csv('/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/lymphoma_CODEX/quantification/processed/kfolds/fold_1_train.csv')\n",
    "df = pd.concat([df1, df2])\n",
    "y = df['encoded_phenotype']\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y), y=y)\n",
    "class_weight_dict = {cls: weight for cls, weight in zip(np.unique(y), class_weights)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lymphoma_CODEX = MultiClassRandomForestClassifier(class_weight=class_weight_dict, n_jobs=-1, random_state=rs, max_depth=25)\n",
    "lymphoma_CODEX.train_and_evaluate_manual(path='/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/lymphoma_CODEX/quantification/processed/kfolds')\n",
    "lymphoma_CODEX.save_results(save_path='/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/lymphoma_CODEX/results_rfc_25', label_path='/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/lymphoma_CODEX/quantification/processed/labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "del lymphoma_CODEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/intestine_CODEX/quantification/processed/kfolds/fold_1_test.csv')\n",
    "df2 = pd.read_csv('/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/intestine_CODEX/quantification/processed/kfolds/fold_1_train.csv')\n",
    "df = pd.concat([df1, df2])\n",
    "y = df['encoded_phenotype']\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y), y=y)\n",
    "class_weight_dict = {cls: weight for cls, weight in zip(np.unique(y), class_weights)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intestine_CODEX = MultiClassRandomForestClassifier(class_weight=class_weight_dict, n_jobs=-1, random_state=rs, max_depth=25)\n",
    "intestine_CODEX.train_and_evaluate_manual(path='/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/intestine_CODEX/quantification/processed/kfolds')\n",
    "intestine_CODEX.save_results(save_path='/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/intestine_CODEX/results_rfc_25', label_path='/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/intestine_CODEX/quantification/processed/labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/feto_maternal/quantification/processed/kfolds/fold_1_test.csv')\n",
    "df2 = pd.read_csv('/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/feto_maternal/quantification/processed/kfolds/fold_1_train.csv')\n",
    "df = pd.concat([df1, df2])\n",
    "y = df['encoded_phenotype']\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y), y=y)\n",
    "class_weight_dict = {cls: weight for cls, weight in zip(np.unique(y), class_weights)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feto_maternal = MultiClassRandomForestClassifier(class_weight=class_weight_dict, n_jobs=-1, random_state=rs, max_depth=25)\n",
    "feto_maternal.train_and_evaluate_manual(path='/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/feto_maternal/quantification/processed/kfolds')\n",
    "feto_maternal.save_results(save_path='/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/feto_maternal/results_rfc_25', label_path='/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/feto_maternal/quantification/processed/labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "del intestine_CODEX, feto_maternal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/CRC_FFPE/quantification/processed/kfolds/fold_1_test.csv')\n",
    "df2 = pd.read_csv('/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/CRC_FFPE/quantification/processed/kfolds/fold_1_train.csv')\n",
    "df = pd.concat([df1, df2])\n",
    "y = df['encoded_phenotype']\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y), y=y)\n",
    "class_weight_dict = {cls: weight for cls, weight in zip(np.unique(y), class_weights)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CRC_FFPE = MultiClassRandomForestClassifier(class_weight=class_weight_dict, n_jobs=-1, random_state=rs, max_depth=25)\n",
    "CRC_FFPE.train_and_evaluate_manual(path='/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/CRC_FFPE/quantification/processed/kfolds')\n",
    "CRC_FFPE.save_results(save_path='/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/CRC_FFPE/results_rfc_25', label_path='/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/CRC_FFPE/quantification/processed/labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df1 = pd.read_csv('/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/BA_CODEX/quantification/BE_tonsil/processed/kfolds/fold_1_test.csv')\n",
    "df2 = pd.read_csv('/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/BA_CODEX/quantification/BE_tonsil/processed/kfolds/fold_1_train.csv')\n",
    "df = pd.concat([df1, df2])\n",
    "y = df['encoded_phenotype']\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y), y=y)\n",
    "class_weight_dict = {cls: weight for cls, weight in zip(np.unique(y), class_weights)}\n",
    "BE_tonsil = MultiClassRandomForestClassifier(class_weight=class_weight_dict, n_jobs=-1, random_state=rs, max_depth=25)\n",
    "BE_tonsil.train_and_evaluate_manual(path='/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/BA_CODEX/quantification/BE_tonsil/processed/kfolds')\n",
    "BE_tonsil.save_results(save_path='/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/BA_CODEX/quantification/BE_tonsil/results_rfc_25', label_path='/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/BA_CODEX/quantification/BE_tonsil/processed/labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/BA_CODEX/quantification/tonsil_training/processed/kfolds/fold_1_test.csv')\n",
    "df2 = pd.read_csv('/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/BA_CODEX/quantification/tonsil_training/processed/kfolds/fold_1_train.csv')\n",
    "df = pd.concat([df1, df2])\n",
    "y = df['encoded_phenotype']\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y), y=y)\n",
    "class_weight_dict = {cls: weight for cls, weight in zip(np.unique(y), class_weights)}\n",
    "tonsil_training = MultiClassRandomForestClassifier(class_weight=class_weight_dict, n_jobs=-1, random_state=rs, max_depth=25)\n",
    "tonsil_training.train_and_evaluate_manual(path='/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/BA_CODEX/quantification/tonsil_training/processed/kfolds')\n",
    "tonsil_training.save_results(save_path='/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/BA_CODEX/quantification/tonsil_training/results_rfc_25', label_path='/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/BA_CODEX/quantification/tonsil_training/processed/labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/AML_bone_marrow/quantification/AML/processed/kfolds/fold_1_test.csv')\n",
    "df2 = pd.read_csv('/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/AML_bone_marrow/quantification/AML/processed/kfolds/fold_1_train.csv')\n",
    "df = pd.concat([df1, df2])\n",
    "y = df['encoded_phenotype']\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y), y=y)\n",
    "class_weight_dict = {cls: weight for cls, weight in zip(np.unique(y), class_weights)}\n",
    "AML = MultiClassRandomForestClassifier(class_weight=class_weight_dict, n_jobs=-1, random_state=rs, max_depth=25)\n",
    "AML.train_and_evaluate_manual(path='/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/AML_bone_marrow/quantification/AML/processed/kfolds')\n",
    "AML.save_results(save_path='/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/AML_bone_marrow/quantification/AML/results_rfc_25', label_path='/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/AML_bone_marrow/quantification/AML/processed/labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/AML_bone_marrow/quantification/healthy_BM/processed/kfolds/fold_1_test.csv')\n",
    "df2 = pd.read_csv('/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/AML_bone_marrow/quantification/healthy_BM/processed/kfolds/fold_1_train.csv')\n",
    "df = pd.concat([df1, df2])\n",
    "y = df['encoded_phenotype']\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y), y=y)\n",
    "class_weight_dict = {cls: weight for cls, weight in zip(np.unique(y), class_weights)}\n",
    "healthy_BM = MultiClassRandomForestClassifier(class_weight=class_weight_dict, n_jobs=-1, random_state=rs, max_depth=25)\n",
    "healthy_BM.train_and_evaluate_manual(path='/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/AML_bone_marrow/quantification/healthy_BM/processed/kfolds')\n",
    "healthy_BM.save_results(save_path='/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/AML_bone_marrow/quantification/healthy_BM/results_rfc_25', label_path='/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/AML_bone_marrow/quantification/healthy_BM/processed/labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cML_benchmark",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
