{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from models_classes.gridsearch_multi import Tune_Eval\n",
    "import pandas as pd\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = 20240925\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 250],\n",
    "    'max_depth': [20, 25, 30, 40],\n",
    "    'min_samples_split' : [2, 3],\n",
    "    'min_samples_leaf' : [1, 2]\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/Maps_data/cHL_2_MIBI/quantification/processed/kfolds/fold_1_test.csv')\n",
    "df2 = pd.read_csv('/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/Maps_data/cHL_2_MIBI/quantification/processed/kfolds/fold_1_train.csv')\n",
    "df = pd.concat([df1, df2])\n",
    "y = df['encoded_phenotype']\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y), y=y)\n",
    "class_weight_dict = {cls: weight for cls, weight in zip(np.unique(y), class_weights)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cHL2 = Tune_Eval(class_weight=class_weight_dict, random_state=rs, model='random_forest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cHL2.train_tune_evaluate(path='/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/Maps_data/cHL_2_MIBI/quantification/processed/kfolds', param_grid = param_grid, n_processes = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cHL2.save_results(save_path='/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/Maps_data/cHL_2_MIBI/results_rfc_25', label_path='/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/Maps_data/cHL_2_MIBI/quantification/processed/labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/Maps_data/cHL_1_MIBI/quantification/processed/kfolds/fold_1_test.csv')\n",
    "df2 = pd.read_csv('/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/Maps_data/cHL_1_MIBI/quantification/processed/kfolds/fold_1_train.csv')\n",
    "df = pd.concat([df1, df2])\n",
    "y = df['encoded_phenotype']\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y), y=y)\n",
    "class_weight_dict = {cls: weight for cls, weight in zip(np.unique(y), class_weights)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GirdSearcher class initialized successfully with the following model parameters:\n",
      "Random State: 20240925\n",
      "Model: RandomForestClassifier(class_weight={np.int64(0): np.float64(0.5850765213693658),\n",
      "                                     np.int64(1): np.float64(0.26086365295389957),\n",
      "                                     np.int64(2): np.float64(0.4695032333921223),\n",
      "                                     np.int64(3): np.float64(1.6965497972642216),\n",
      "                                     np.int64(4): np.float64(12.176582698044415),\n",
      "                                     np.int64(5): np.float64(1.0538473564708768),\n",
      "                                     np.int64(6): np.float64(4.916489899158877),\n",
      "                                     np.int64(7): np.float64(8.88982322835122),\n",
      "                                     np.int64(8): np.float64(0.5341720799874952),\n",
      "                                     np.int64(9): np.float64(4.060273987742945),\n",
      "                                     np.int64(10): np.float64(6.450872279340105),\n",
      "                                     np.int64(11): np.float64(0.9075844605027484),\n",
      "                                     np.int64(12): np.float64(1.885434576201596),\n",
      "                                     np.int64(13): np.float64(2.0594137943599358)},\n",
      "                       criterion='log_loss', n_jobs=2, random_state=20240925)\n"
     ]
    }
   ],
   "source": [
    "cHL1 = Tune_Eval(class_weight=class_weight_dict, random_state=rs, model='random_forest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taking data from fold_1_train.csv and fold_1_test.csv for fold 1. No NANs found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 1:   0%|          | 0/32 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcHL1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_tune_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/Maps_data/cHL_1_MIBI/quantification/processed/kfolds\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_processes\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/PhD_Schapiro/Projects/phenotype_benchmark/github/pheno_benchmark_small/src/models_classes/gridsearch_multi.py:129\u001b[0m, in \u001b[0;36mTune_Eval.train_tune_evaluate\u001b[0;34m(self, path, param_grid, dumb_nonnumericals, n_processes, drop_xy)\u001b[0m\n\u001b[1;32m    127\u001b[0m param_combinations \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(param_grid\u001b[38;5;241m.\u001b[39mkeys(), v)) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m itertools\u001b[38;5;241m.\u001b[39mproduct(\u001b[38;5;241m*\u001b[39mparam_grid\u001b[38;5;241m.\u001b[39mvalues())]\n\u001b[1;32m    128\u001b[0m args \u001b[38;5;241m=\u001b[39m [(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, X_train_scaled, y_train, X_val_scaled, y_val, param) \u001b[38;5;28;01mfor\u001b[39;00m param \u001b[38;5;129;01min\u001b[39;00m param_combinations]\n\u001b[0;32m--> 129\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_processes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mFold \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m accuracy, model, params \u001b[38;5;129;01min\u001b[39;00m results:\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m accuracy \u001b[38;5;241m>\u001b[39m best_score:\n",
      "File \u001b[0;32m~/miniforge3/envs/cML_benchmark/lib/python3.10/site-packages/joblib/parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[1;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/cML_benchmark/lib/python3.10/site-packages/joblib/parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/cML_benchmark/lib/python3.10/site-packages/joblib/parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[1;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cHL1.train_tune_evaluate(path='/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/Maps_data/cHL_1_MIBI/quantification/processed/kfolds', param_grid = param_grid, n_processes = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cHL1.save_results(save_path='/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/Maps_data/cHL_1_MIBI/results_rfc_25', label_path='/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/Maps_data/cHL_1_MIBI/quantification/processed/labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/Maps_data/cHL_CODEX/quantification/processed/kfolds/fold_1_test.csv')\n",
    "df2 = pd.read_csv('/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/Maps_data/cHL_CODEX/quantification/processed/kfolds/fold_1_train.csv')\n",
    "df = pd.concat([df1, df2])\n",
    "y = df['encoded_phenotype']\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y), y=y)\n",
    "class_weight_dict = {cls: weight for cls, weight in zip(np.unique(y), class_weights)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cHL_CODEX = MultiClassRandomForestClassifier(class_weight=class_weight_dict, n_jobs=-1, random_state=rs, max_depth=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cHL_CODEX.train_and_evaluate_manual(path='/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/Maps_data/cHL_CODEX/quantification/processed/kfolds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cHL_CODEX.save_results(save_path='/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/Maps_data/cHL_CODEX/results_rfc_25', label_path='/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/Maps_data/cHL_CODEX/quantification/processed/labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/MRL_CODEX/quantification/processed/kfolds/fold_1_test.csv')\n",
    "df2 = pd.read_csv('/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/MRL_CODEX/quantification/processed/kfolds/fold_1_train.csv')\n",
    "df = pd.concat([df1, df2])\n",
    "y = df['encoded_phenotype']\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y), y=y)\n",
    "class_weight_dict = {cls: weight for cls, weight in zip(np.unique(y), class_weights)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MRL_CODEX = MultiClassRandomForestClassifier(class_weight=class_weight_dict, n_jobs=-1, random_state=rs, max_depth=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MRL_CODEX.train_and_evaluate_manual(path='/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/MRL_CODEX/quantification/processed/kfolds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MRL_CODEX.save_results(save_path='/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/MRL_CODEX/results_rfc_25', label_path='/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/MRL_CODEX/quantification/processed/labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/TB_MIBI_atlas/quantification/processed/sarc/kfolds/fold_1_test.csv')\n",
    "df2 = pd.read_csv('/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/TB_MIBI_atlas/quantification/processed/sarc/kfolds/fold_1_train.csv')\n",
    "df = pd.concat([df1, df2])\n",
    "y = df['encoded_phenotype']\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y), y=y)\n",
    "class_weight_dict = {cls: weight for cls, weight in zip(np.unique(y), class_weights)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sarc = MultiClassRandomForestClassifier(class_weight=class_weight_dict, n_jobs=-1, random_state=rs, max_depth=25)\n",
    "sarc.train_and_evaluate_manual(path='/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/TB_MIBI_atlas/quantification/processed/sarc/kfolds')\n",
    "sarc.save_results(save_path='/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/TB_MIBI_atlas/quantification/processed/sarc/results_rfc_25', label_path='/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/TB_MIBI_atlas/quantification/processed/sarc/labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/TB_MIBI_atlas/quantification/processed/TB/kfolds/fold_1_test.csv')\n",
    "df2 = pd.read_csv('/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/TB_MIBI_atlas/quantification/processed/TB/kfolds/fold_1_train.csv')\n",
    "df = pd.concat([df1, df2])\n",
    "y = df['encoded_phenotype']\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y), y=y)\n",
    "class_weight_dict = {cls: weight for cls, weight in zip(np.unique(y), class_weights)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb = MultiClassRandomForestClassifier(class_weight=class_weight_dict, n_jobs=-1, random_state=rs, max_depth=25)\n",
    "tb.train_and_evaluate_manual(path='/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/TB_MIBI_atlas/quantification/processed/TB/kfolds')\n",
    "tb.save_results(save_path='/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/TB_MIBI_atlas/quantification/processed/TB/results_rfc_25', label_path='/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/TB_MIBI_atlas/quantification/processed/TB/labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/tonsil_CODEX/quantification/processed/kfolds/fold_1_test.csv')\n",
    "df2 = pd.read_csv('/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/tonsil_CODEX/quantification/processed/kfolds/fold_1_train.csv')\n",
    "df = pd.concat([df1, df2])\n",
    "y = df['encoded_phenotype']\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y), y=y)\n",
    "class_weight_dict = {cls: weight for cls, weight in zip(np.unique(y), class_weights)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tonsil_CODEX = MultiClassRandomForestClassifier(class_weight=class_weight_dict, n_jobs=-1, random_state=rs, max_depth=25)\n",
    "tonsil_CODEX.train_and_evaluate_manual(path='/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/tonsil_CODEX/quantification/processed/kfolds')\n",
    "tonsil_CODEX.save_results(save_path='/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/tonsil_CODEX/results_rfc_25', label_path='/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/tonsil_CODEX/quantification/processed/labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/tonsil_CODEX2/quantification/processed/kfolds/fold_1_test.csv')\n",
    "df2 = pd.read_csv('/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/tonsil_CODEX2/quantification/processed/kfolds/fold_1_train.csv')\n",
    "df = pd.concat([df1, df2])\n",
    "y = df['encoded_phenotype']\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y), y=y)\n",
    "class_weight_dict = {cls: weight for cls, weight in zip(np.unique(y), class_weights)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tonsil_CODEX2 = MultiClassRandomForestClassifier(class_weight=class_weight_dict, n_jobs=-1, random_state=rs, max_depth=25)\n",
    "tonsil_CODEX2.train_and_evaluate_manual(path='/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/tonsil_CODEX2/quantification/processed/kfolds')\n",
    "tonsil_CODEX2.save_results(save_path='/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/tonsil_CODEX2/results_rfc_25', label_path='/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/tonsil_CODEX2/quantification/processed/labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "del cHL1, cHL2, cHL_CODEX, MRL_CODEX, sarc, tb, tonsil_CODEX, tonsil_CODEX2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/lymphoma_CODEX/quantification/processed/kfolds/fold_1_test.csv')\n",
    "df2 = pd.read_csv('/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/lymphoma_CODEX/quantification/processed/kfolds/fold_1_train.csv')\n",
    "df = pd.concat([df1, df2])\n",
    "y = df['encoded_phenotype']\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y), y=y)\n",
    "class_weight_dict = {cls: weight for cls, weight in zip(np.unique(y), class_weights)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lymphoma_CODEX = MultiClassRandomForestClassifier(class_weight=class_weight_dict, n_jobs=-1, random_state=rs, max_depth=25)\n",
    "lymphoma_CODEX.train_and_evaluate_manual(path='/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/lymphoma_CODEX/quantification/processed/kfolds')\n",
    "lymphoma_CODEX.save_results(save_path='/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/lymphoma_CODEX/results_rfc_25', label_path='/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/lymphoma_CODEX/quantification/processed/labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "del lymphoma_CODEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/intestine_CODEX/quantification/processed/kfolds/fold_1_test.csv')\n",
    "df2 = pd.read_csv('/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/intestine_CODEX/quantification/processed/kfolds/fold_1_train.csv')\n",
    "df = pd.concat([df1, df2])\n",
    "y = df['encoded_phenotype']\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y), y=y)\n",
    "class_weight_dict = {cls: weight for cls, weight in zip(np.unique(y), class_weights)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intestine_CODEX = MultiClassRandomForestClassifier(class_weight=class_weight_dict, n_jobs=-1, random_state=rs, max_depth=25)\n",
    "intestine_CODEX.train_and_evaluate_manual(path='/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/intestine_CODEX/quantification/processed/kfolds')\n",
    "intestine_CODEX.save_results(save_path='/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/intestine_CODEX/results_rfc_25', label_path='/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/intestine_CODEX/quantification/processed/labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/feto_maternal/quantification/processed/kfolds/fold_1_test.csv')\n",
    "df2 = pd.read_csv('/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/feto_maternal/quantification/processed/kfolds/fold_1_train.csv')\n",
    "df = pd.concat([df1, df2])\n",
    "y = df['encoded_phenotype']\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y), y=y)\n",
    "class_weight_dict = {cls: weight for cls, weight in zip(np.unique(y), class_weights)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feto_maternal = MultiClassRandomForestClassifier(class_weight=class_weight_dict, n_jobs=-1, random_state=rs, max_depth=25)\n",
    "feto_maternal.train_and_evaluate_manual(path='/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/feto_maternal/quantification/processed/kfolds')\n",
    "feto_maternal.save_results(save_path='/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/feto_maternal/results_rfc_25', label_path='/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/feto_maternal/quantification/processed/labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "del intestine_CODEX, feto_maternal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/CRC_FFPE/quantification/processed/kfolds/fold_1_test.csv')\n",
    "df2 = pd.read_csv('/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/CRC_FFPE/quantification/processed/kfolds/fold_1_train.csv')\n",
    "df = pd.concat([df1, df2])\n",
    "y = df['encoded_phenotype']\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y), y=y)\n",
    "class_weight_dict = {cls: weight for cls, weight in zip(np.unique(y), class_weights)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CRC_FFPE = MultiClassRandomForestClassifier(class_weight=class_weight_dict, n_jobs=-1, random_state=rs, max_depth=25)\n",
    "CRC_FFPE.train_and_evaluate_manual(path='/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/CRC_FFPE/quantification/processed/kfolds')\n",
    "CRC_FFPE.save_results(save_path='/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/CRC_FFPE/results_rfc_25', label_path='/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/CRC_FFPE/quantification/processed/labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df1 = pd.read_csv('/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/BA_CODEX/quantification/BE_tonsil/processed/kfolds/fold_1_test.csv')\n",
    "df2 = pd.read_csv('/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/BA_CODEX/quantification/BE_tonsil/processed/kfolds/fold_1_train.csv')\n",
    "df = pd.concat([df1, df2])\n",
    "y = df['encoded_phenotype']\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y), y=y)\n",
    "class_weight_dict = {cls: weight for cls, weight in zip(np.unique(y), class_weights)}\n",
    "BE_tonsil = MultiClassRandomForestClassifier(class_weight=class_weight_dict, n_jobs=-1, random_state=rs, max_depth=25)\n",
    "BE_tonsil.train_and_evaluate_manual(path='/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/BA_CODEX/quantification/BE_tonsil/processed/kfolds')\n",
    "BE_tonsil.save_results(save_path='/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/BA_CODEX/quantification/BE_tonsil/results_rfc_25', label_path='/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/BA_CODEX/quantification/BE_tonsil/processed/labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/BA_CODEX/quantification/tonsil_training/processed/kfolds/fold_1_test.csv')\n",
    "df2 = pd.read_csv('/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/BA_CODEX/quantification/tonsil_training/processed/kfolds/fold_1_train.csv')\n",
    "df = pd.concat([df1, df2])\n",
    "y = df['encoded_phenotype']\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y), y=y)\n",
    "class_weight_dict = {cls: weight for cls, weight in zip(np.unique(y), class_weights)}\n",
    "tonsil_training = MultiClassRandomForestClassifier(class_weight=class_weight_dict, n_jobs=-1, random_state=rs, max_depth=25)\n",
    "tonsil_training.train_and_evaluate_manual(path='/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/BA_CODEX/quantification/tonsil_training/processed/kfolds')\n",
    "tonsil_training.save_results(save_path='/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/BA_CODEX/quantification/tonsil_training/results_rfc_25', label_path='/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/BA_CODEX/quantification/tonsil_training/processed/labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/AML_bone_marrow/quantification/AML/processed/kfolds/fold_1_test.csv')\n",
    "df2 = pd.read_csv('/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/AML_bone_marrow/quantification/AML/processed/kfolds/fold_1_train.csv')\n",
    "df = pd.concat([df1, df2])\n",
    "y = df['encoded_phenotype']\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y), y=y)\n",
    "class_weight_dict = {cls: weight for cls, weight in zip(np.unique(y), class_weights)}\n",
    "AML = MultiClassRandomForestClassifier(class_weight=class_weight_dict, n_jobs=-1, random_state=rs, max_depth=25)\n",
    "AML.train_and_evaluate_manual(path='/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/AML_bone_marrow/quantification/AML/processed/kfolds')\n",
    "AML.save_results(save_path='/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/AML_bone_marrow/quantification/AML/results_rfc_25', label_path='/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/AML_bone_marrow/quantification/AML/processed/labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/AML_bone_marrow/quantification/healthy_BM/processed/kfolds/fold_1_test.csv')\n",
    "df2 = pd.read_csv('/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/AML_bone_marrow/quantification/healthy_BM/processed/kfolds/fold_1_train.csv')\n",
    "df = pd.concat([df1, df2])\n",
    "y = df['encoded_phenotype']\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y), y=y)\n",
    "class_weight_dict = {cls: weight for cls, weight in zip(np.unique(y), class_weights)}\n",
    "healthy_BM = MultiClassRandomForestClassifier(class_weight=class_weight_dict, n_jobs=-1, random_state=rs, max_depth=25)\n",
    "healthy_BM.train_and_evaluate_manual(path='/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/AML_bone_marrow/quantification/healthy_BM/processed/kfolds')\n",
    "healthy_BM.save_results(save_path='/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/AML_bone_marrow/quantification/healthy_BM/results_rfc_25', label_path='/Volumes/Lukas_SSD/phenotyping_benchmark/datasets/AML_bone_marrow/quantification/healthy_BM/processed/labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cML_benchmark",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
